{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데모"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:38:53.774831Z",
     "start_time": "2020-10-05T08:38:53.486186Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:53:10.431515Z",
     "start_time": "2020-10-05T08:53:10.398638Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import optuna.integration.lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:38:55.047271Z",
     "start_time": "2020-10-05T08:38:55.018323Z"
    }
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[03-pandas-eda.ipynb](https://github.com/kaggler-tv/dku-kaggle-class/blob/master/notebook/03-pandas-eda.ipynb)에서 생성한 `feature.csv` 피처파일 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:38:55.079180Z",
     "start_time": "2020-10-05T08:38:55.050994Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path('./data/')\n",
    "\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'class'\n",
    "n_fold = 10\n",
    "n_class = 3\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:38:55.109220Z",
     "start_time": "2020-10-05T08:38:55.081365Z"
    }
   },
   "outputs": [],
   "source": [
    "algo_name = 'lgb_optuna'\n",
    "feature_name = 'feature'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = data_dir / f'{feature_name}.csv'\n",
    "p_val_file = data_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = data_dir / f'{model_name}.tst.csv'\n",
    "sub_file = data_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:38:56.480522Z",
     "start_time": "2020-10-05T08:38:55.111305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>dered_u</th>\n",
       "      <th>dered_g</th>\n",
       "      <th>dered_r</th>\n",
       "      <th>dered_i</th>\n",
       "      <th>dered_z</th>\n",
       "      <th>nObserve</th>\n",
       "      <th>airmass_u</th>\n",
       "      <th>class</th>\n",
       "      <th>d_dered_u</th>\n",
       "      <th>d_dered_g</th>\n",
       "      <th>d_dered_r</th>\n",
       "      <th>d_dered_i</th>\n",
       "      <th>d_dered_z</th>\n",
       "      <th>d_dered_zi</th>\n",
       "      <th>d_dered_zr</th>\n",
       "      <th>d_dered_zg</th>\n",
       "      <th>d_dered_zu</th>\n",
       "      <th>d_dered_ir</th>\n",
       "      <th>d_dered_ig</th>\n",
       "      <th>d_dered_iu</th>\n",
       "      <th>d_dered_ru</th>\n",
       "      <th>d_dered_gu</th>\n",
       "      <th>d_obs_det</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.9396</td>\n",
       "      <td>-8.1086e-05</td>\n",
       "      <td>23.1243</td>\n",
       "      <td>20.2578</td>\n",
       "      <td>18.9551</td>\n",
       "      <td>17.6321</td>\n",
       "      <td>16.9089</td>\n",
       "      <td>2.9444</td>\n",
       "      <td>1.1898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1397</td>\n",
       "      <td>-0.0790</td>\n",
       "      <td>-0.0544</td>\n",
       "      <td>-0.0403</td>\n",
       "      <td>-0.0307</td>\n",
       "      <td>-0.7232</td>\n",
       "      <td>-2.0462</td>\n",
       "      <td>-3.3488</td>\n",
       "      <td>-6.2153</td>\n",
       "      <td>-1.3230</td>\n",
       "      <td>-2.6257</td>\n",
       "      <td>-5.4921</td>\n",
       "      <td>-4.1691</td>\n",
       "      <td>-2.8665</td>\n",
       "      <td>6.1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.1689</td>\n",
       "      <td>4.5061e-03</td>\n",
       "      <td>14.9664</td>\n",
       "      <td>14.0045</td>\n",
       "      <td>13.4114</td>\n",
       "      <td>13.2363</td>\n",
       "      <td>13.1347</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>1.2533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0857</td>\n",
       "      <td>-0.0574</td>\n",
       "      <td>-0.0410</td>\n",
       "      <td>-0.0322</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>-0.1016</td>\n",
       "      <td>-0.2767</td>\n",
       "      <td>-0.8698</td>\n",
       "      <td>-1.8317</td>\n",
       "      <td>-0.1751</td>\n",
       "      <td>-0.7683</td>\n",
       "      <td>-1.7302</td>\n",
       "      <td>-1.5550</td>\n",
       "      <td>-0.9619</td>\n",
       "      <td>1.4427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.3500</td>\n",
       "      <td>4.7198e-04</td>\n",
       "      <td>16.6076</td>\n",
       "      <td>15.6866</td>\n",
       "      <td>15.4400</td>\n",
       "      <td>15.3217</td>\n",
       "      <td>15.2961</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>1.0225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1787</td>\n",
       "      <td>-0.1388</td>\n",
       "      <td>-0.0963</td>\n",
       "      <td>-0.0718</td>\n",
       "      <td>-0.0540</td>\n",
       "      <td>-0.0257</td>\n",
       "      <td>-0.1440</td>\n",
       "      <td>-0.3905</td>\n",
       "      <td>-1.3116</td>\n",
       "      <td>-0.1183</td>\n",
       "      <td>-0.3649</td>\n",
       "      <td>-1.2859</td>\n",
       "      <td>-1.1676</td>\n",
       "      <td>-0.9211</td>\n",
       "      <td>1.8205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.6346</td>\n",
       "      <td>5.8143e-06</td>\n",
       "      <td>25.3536</td>\n",
       "      <td>20.9947</td>\n",
       "      <td>20.0873</td>\n",
       "      <td>19.7947</td>\n",
       "      <td>19.5552</td>\n",
       "      <td>1.6094</td>\n",
       "      <td>1.2054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3070</td>\n",
       "      <td>-0.1941</td>\n",
       "      <td>-0.1339</td>\n",
       "      <td>-0.1003</td>\n",
       "      <td>-0.0795</td>\n",
       "      <td>-0.2395</td>\n",
       "      <td>-0.5321</td>\n",
       "      <td>-1.4395</td>\n",
       "      <td>-5.7985</td>\n",
       "      <td>-0.2926</td>\n",
       "      <td>-1.2000</td>\n",
       "      <td>-5.5590</td>\n",
       "      <td>-5.2664</td>\n",
       "      <td>-4.3590</td>\n",
       "      <td>1.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.9826</td>\n",
       "      <td>-3.3247e-05</td>\n",
       "      <td>23.7714</td>\n",
       "      <td>20.4338</td>\n",
       "      <td>18.8630</td>\n",
       "      <td>18.1903</td>\n",
       "      <td>17.8759</td>\n",
       "      <td>2.6391</td>\n",
       "      <td>1.1939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6820</td>\n",
       "      <td>-0.2653</td>\n",
       "      <td>-0.1794</td>\n",
       "      <td>-0.1339</td>\n",
       "      <td>-0.1067</td>\n",
       "      <td>-0.3144</td>\n",
       "      <td>-0.9871</td>\n",
       "      <td>-2.5579</td>\n",
       "      <td>-5.8955</td>\n",
       "      <td>-0.6727</td>\n",
       "      <td>-2.2436</td>\n",
       "      <td>-5.5811</td>\n",
       "      <td>-4.9084</td>\n",
       "      <td>-3.3376</td>\n",
       "      <td>4.5471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          z    redshift  dered_u  dered_g  dered_r  dered_i  dered_z  \\\n",
       "id                                                                     \n",
       "0   16.9396 -8.1086e-05  23.1243  20.2578  18.9551  17.6321  16.9089   \n",
       "1   13.1689  4.5061e-03  14.9664  14.0045  13.4114  13.2363  13.1347   \n",
       "2   15.3500  4.7198e-04  16.6076  15.6866  15.4400  15.3217  15.2961   \n",
       "3   19.6346  5.8143e-06  25.3536  20.9947  20.0873  19.7947  19.5552   \n",
       "4   17.9826 -3.3247e-05  23.7714  20.4338  18.8630  18.1903  17.8759   \n",
       "\n",
       "    nObserve  airmass_u  class  d_dered_u  d_dered_g  d_dered_r  d_dered_i  \\\n",
       "id                                                                           \n",
       "0     2.9444     1.1898    0.0    -0.1397    -0.0790    -0.0544    -0.0403   \n",
       "1     0.6931     1.2533    1.0    -0.0857    -0.0574    -0.0410    -0.0322   \n",
       "2     1.0986     1.0225    0.0    -0.1787    -0.1388    -0.0963    -0.0718   \n",
       "3     1.6094     1.2054    0.0    -0.3070    -0.1941    -0.1339    -0.1003   \n",
       "4     2.6391     1.1939    0.0    -0.6820    -0.2653    -0.1794    -0.1339   \n",
       "\n",
       "    d_dered_z  d_dered_zi  d_dered_zr  d_dered_zg  d_dered_zu  d_dered_ir  \\\n",
       "id                                                                          \n",
       "0     -0.0307     -0.7232     -2.0462     -3.3488     -6.2153     -1.3230   \n",
       "1     -0.0343     -0.1016     -0.2767     -0.8698     -1.8317     -0.1751   \n",
       "2     -0.0540     -0.0257     -0.1440     -0.3905     -1.3116     -0.1183   \n",
       "3     -0.0795     -0.2395     -0.5321     -1.4395     -5.7985     -0.2926   \n",
       "4     -0.1067     -0.3144     -0.9871     -2.5579     -5.8955     -0.6727   \n",
       "\n",
       "    d_dered_ig  d_dered_iu  d_dered_ru  d_dered_gu  d_obs_det  \n",
       "id                                                             \n",
       "0      -2.6257     -5.4921     -4.1691     -2.8665     6.1132  \n",
       "1      -0.7683     -1.7302     -1.5550     -0.9619     1.4427  \n",
       "2      -0.3649     -1.2859     -1.1676     -0.9211     1.8205  \n",
       "3      -1.2000     -5.5590     -5.2664     -4.3590     1.8640  \n",
       "4      -2.2436     -5.5811     -4.9084     -3.3376     4.5471  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(feature_file, index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:38:56.553068Z",
     "start_time": "2020-10-05T08:38:56.482710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000,) (320000, 24) (80000, 24)\n"
     ]
    }
   ],
   "source": [
    "y = df[target_col].values[:320000]\n",
    "df.drop(target_col, axis=1, inplace=True)\n",
    "trn = df.iloc[:320000].values\n",
    "tst = df.iloc[320000:].values\n",
    "feature_name = df.columns.tolist()\n",
    "print(y.shape, trn.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:38:56.690768Z",
     "start_time": "2020-10-05T08:38:56.556065Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(trn, y, test_size=.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:38:56.723614Z",
     "start_time": "2020-10-05T08:38:56.693535Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"max_depth\" : 30,\n",
    "    \"num_class\": 3,\n",
    "    \"n_estimators\": 16000,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"lambda_l1\": 0.,\n",
    "    \"lambda_l2\": 0.,\n",
    "    \"random_state\": seed,\n",
    "    \"n_jobs\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:51:30.834862Z",
     "start_time": "2020-10-05T08:38:56.725742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 20:47:32,166] A new study created in memory with name: no-name-328c31ea-c283-47f3-8f76-9610f836755f\n",
      "feature_fraction, val_score: inf:   0%|                                                                                                                                                                             | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5804\n",
      "[LightGBM] [Info] Number of data points in the train set: 224000, number of used features: 24\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Info] Start training from score -0.980377\n",
      "[LightGBM] [Info] Start training from score -2.010849\n",
      "[LightGBM] [Info] Start training from score -0.711402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.144495\tvalid_1's multi_logloss: 0.164085\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's multi_logloss: 0.146941\tvalid_1's multi_logloss: 0.16273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.162730:  14%|######################8                                                                                                                                         | 1/7 [00:12<01:16, 12.72s/it][I 2020-10-08 20:47:44,893] Trial 0 finished with value: 0.16272976895093316 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.16272976895093316.\n",
      "feature_fraction, val_score: 0.162730:  14%|######################8                                                                                                                                         | 1/7 [00:12<01:16, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5804\n",
      "[LightGBM] [Info] Number of data points in the train set: 224000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.980377\n",
      "[LightGBM] [Info] Start training from score -2.010849\n",
      "[LightGBM] [Info] Start training from score -0.711402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.14481\tvalid_1's multi_logloss: 0.161905\n",
      "[200]\ttraining's multi_logloss: 0.130938\tvalid_1's multi_logloss: 0.159855\n",
      "[300]\ttraining's multi_logloss: 0.121003\tvalid_1's multi_logloss: 0.159475\n",
      "[400]\ttraining's multi_logloss: 0.113148\tvalid_1's multi_logloss: 0.159593\n",
      "Early stopping, best iteration is:\n",
      "[312]\ttraining's multi_logloss: 0.120015\tvalid_1's multi_logloss: 0.159466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.159466:  29%|#############################################7                                                                                                                  | 2/7 [00:25<01:03, 12.75s/it][I 2020-10-08 20:47:57,706] Trial 1 finished with value: 0.15946614828640482 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.15946614828640482.\n",
      "feature_fraction, val_score: 0.159466:  29%|#############################################7                                                                                                                  | 2/7 [00:25<01:03, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5804\n",
      "[LightGBM] [Info] Number of data points in the train set: 224000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.980377\n",
      "[LightGBM] [Info] Start training from score -2.010849\n",
      "[LightGBM] [Info] Start training from score -0.711402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.142976\tvalid_1's multi_logloss: 0.16287\n",
      "[200]\ttraining's multi_logloss: 0.129254\tvalid_1's multi_logloss: 0.160867\n",
      "[300]\ttraining's multi_logloss: 0.118974\tvalid_1's multi_logloss: 0.160697\n",
      "Early stopping, best iteration is:\n",
      "[288]\ttraining's multi_logloss: 0.12012\tvalid_1's multi_logloss: 0.160665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.159466:  43%|####################################################################5                                                                                           | 3/7 [00:38<00:50, 12.67s/it][I 2020-10-08 20:48:10,204] Trial 2 finished with value: 0.16066486152962167 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.15946614828640482.\n",
      "feature_fraction, val_score: 0.159466:  43%|####################################################################5                                                                                           | 3/7 [00:38<00:50, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5804\n",
      "[LightGBM] [Info] Number of data points in the train set: 224000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.980377\n",
      "[LightGBM] [Info] Start training from score -2.010849\n",
      "[LightGBM] [Info] Start training from score -0.711402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.147565\tvalid_1's multi_logloss: 0.163428\n",
      "[200]\ttraining's multi_logloss: 0.133\tvalid_1's multi_logloss: 0.160541\n",
      "[300]\ttraining's multi_logloss: 0.123238\tvalid_1's multi_logloss: 0.159998\n",
      "[400]\ttraining's multi_logloss: 0.115439\tvalid_1's multi_logloss: 0.159954\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's multi_logloss: 0.118828\tvalid_1's multi_logloss: 0.159899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.159466:  57%|###########################################################################################4                                                                    | 4/7 [00:51<00:38, 12.82s/it][I 2020-10-08 20:48:23,355] Trial 3 finished with value: 0.15989852990531192 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.15946614828640482.\n",
      "feature_fraction, val_score: 0.159466:  57%|###########################################################################################4                                                                    | 4/7 [00:51<00:38, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5804\n",
      "[LightGBM] [Info] Number of data points in the train set: 224000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.980377\n",
      "[LightGBM] [Info] Start training from score -2.010849\n",
      "[LightGBM] [Info] Start training from score -0.711402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.145672\tvalid_1's multi_logloss: 0.162313\n",
      "[200]\ttraining's multi_logloss: 0.131581\tvalid_1's multi_logloss: 0.160382\n",
      "[300]\ttraining's multi_logloss: 0.122098\tvalid_1's multi_logloss: 0.159989\n",
      "[400]\ttraining's multi_logloss: 0.114082\tvalid_1's multi_logloss: 0.159951\n",
      "Early stopping, best iteration is:\n",
      "[351]\ttraining's multi_logloss: 0.11789\tvalid_1's multi_logloss: 0.159874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.159466:  71%|##################################################################################################################2                                             | 5/7 [01:07<00:27, 13.77s/it][I 2020-10-08 20:48:39,335] Trial 4 finished with value: 0.15987378275575173 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.15946614828640482.\n",
      "feature_fraction, val_score: 0.159466:  71%|##################################################################################################################2                                             | 5/7 [01:07<00:27, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5804\n",
      "[LightGBM] [Info] Number of data points in the train set: 224000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.980377\n",
      "[LightGBM] [Info] Start training from score -2.010849\n",
      "[LightGBM] [Info] Start training from score -0.711402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.143931\tvalid_1's multi_logloss: 0.169879\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's multi_logloss: 0.148152\tvalid_1's multi_logloss: 0.163787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.159466:  86%|#########################################################################################################################################1                      | 6/7 [01:14<00:11, 11.81s/it][I 2020-10-08 20:48:46,579] Trial 5 finished with value: 0.16378709855809553 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.15946614828640482.\n",
      "feature_fraction, val_score: 0.159466:  86%|#########################################################################################################################################1                      | 6/7 [01:14<00:11, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5804\n",
      "[LightGBM] [Info] Number of data points in the train set: 224000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -0.980377\n",
      "[LightGBM] [Info] Start training from score -2.010849\n",
      "[LightGBM] [Info] Start training from score -0.711402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.143278\tvalid_1's multi_logloss: 0.1623\n",
      "[200]\ttraining's multi_logloss: 0.129331\tvalid_1's multi_logloss: 0.160346\n",
      "[300]\ttraining's multi_logloss: 0.119515\tvalid_1's multi_logloss: 0.16029\n",
      "Early stopping, best iteration is:\n",
      "[299]\ttraining's multi_logloss: 0.119592\tvalid_1's multi_logloss: 0.160268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.159466: 100%|################################################################################################################################################################| 7/7 [01:31<00:00, 13.39s/it][I 2020-10-08 20:49:03,659] Trial 6 finished with value: 0.16026799004673434 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.15946614828640482.\n",
      "feature_fraction, val_score: 0.159466: 100%|################################################################################################################################################################| 7/7 [01:31<00:00, 13.07s/it]\n",
      "num_leaves, val_score: 0.159466:   0%|                                                                                                                                                                             | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2020-10-08 20:49:03,680] Trial 7 failed because of the following error: LightGBMError('Check failed: (num_leaves) <= (131072) at D:\\\\a\\\\1\\\\s\\\\python-package\\\\compile\\\\src\\\\io\\\\config_auto.cpp, line 319 .\\n')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\study.py\", line 799, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"c:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\integration\\_lightgbm_tuner\\optimize.py\", line 236, in __call__\n",
      "    booster = lgb.train(self.lgbm_params, self.train_set, **self.lgbm_kwargs)\n",
      "  File \"c:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py\", line 173, in train\n",
      "    train_set._update_params(params) \\\n",
      "  File \"c:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\", line 1436, in _update_params\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Check failed: (num_leaves) <= (131072) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\config_auto.cpp, line 319 .\n",
      "\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: (num_leaves) <= (131072) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\config_auto.cpp, line 319 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b4dfd44fa99a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                   \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                   \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                   early_stopping_rounds=100)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m prediction = np.argmax(model.predict(X_val, num_iteration=model.best_iteration), \n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\integration\\_lightgbm_tuner\\__init__.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mauto_booster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLightGBMTuner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mauto_booster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mauto_booster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_booster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\integration\\_lightgbm_tuner\\optimize.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune_feature_fraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune_num_leaves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune_bagging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune_feature_fraction_stage2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\integration\\_lightgbm_tuner\\optimize.py\u001b[0m in \u001b[0;36mtune_num_leaves\u001b[1;34m(self, n_trials)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtune_num_leaves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tune_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_leaves\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_leaves\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtune_bagging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\integration\\_lightgbm_tuner\\optimize.py\u001b[0m in \u001b[0;36m_tune_params\u001b[1;34m(self, target_param_names, n_trials, sampler, step_name)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         objective = super(LightGBMTuner, self)._tune_params(\n\u001b[1;32m--> 829\u001b[1;33m             \u001b[0mtarget_param_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m         )\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\integration\\_lightgbm_tuner\\optimize.py\u001b[0m in \u001b[0;36m_tune_params\u001b[1;34m(self, target_param_names, n_trials, sampler, step_name)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                 \u001b[0mcatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optuna_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             )\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                 self._optimize_sequential(\n\u001b[1;32m--> 339\u001b[1;33m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                 )\n\u001b[0;32m    341\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    745\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    774\u001b[0m     ) -> None:\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\optuna\\integration\\_lightgbm_tuner\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgbm_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgbm_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mval_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_booster_best_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training only accepts Dataset object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m              \u001b[1;33m.\u001b[0m\u001b[0m_set_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m              \u001b[1;33m.\u001b[0m\u001b[0mset_feature_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82102\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_update_params\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m   1434\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_free_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1437\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Check failed: (num_leaves) <= (131072) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\config_auto.cpp, line 319 .\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(X_trn, label=y_trn)\n",
    "dval = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "model = lgb.train(params, \n",
    "                  dtrain, \n",
    "                  valid_sets=[dtrain, dval], \n",
    "                  verbose_eval=100, \n",
    "                  early_stopping_rounds=100)\n",
    "\n",
    "prediction = np.argmax(model.predict(X_val, num_iteration=model.best_iteration), \n",
    "                       axis=1)\n",
    "accuracy = accuracy_score(y_val, prediction)\n",
    "\n",
    "params = model.params\n",
    "print(\"Best params:\", params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")\n",
    "for key, value in params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:51:30.898328Z",
     "start_time": "2020-10-05T08:51:30.838172Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:00.359900Z",
     "start_time": "2020-10-05T08:53:24.061986Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.848612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.743166\n",
      "[3]\tvalid_0's multi_logloss: 0.656242\n",
      "[4]\tvalid_0's multi_logloss: 0.587709\n",
      "[5]\tvalid_0's multi_logloss: 0.533443\n",
      "[6]\tvalid_0's multi_logloss: 0.485747\n",
      "[7]\tvalid_0's multi_logloss: 0.448572\n",
      "[8]\tvalid_0's multi_logloss: 0.412421\n",
      "[9]\tvalid_0's multi_logloss: 0.379774\n",
      "[10]\tvalid_0's multi_logloss: 0.353635\n",
      "[11]\tvalid_0's multi_logloss: 0.332668\n",
      "[12]\tvalid_0's multi_logloss: 0.314568\n",
      "[13]\tvalid_0's multi_logloss: 0.297665\n",
      "[14]\tvalid_0's multi_logloss: 0.282573\n",
      "[15]\tvalid_0's multi_logloss: 0.270287\n",
      "[16]\tvalid_0's multi_logloss: 0.25904\n",
      "[17]\tvalid_0's multi_logloss: 0.248601\n",
      "[18]\tvalid_0's multi_logloss: 0.237986\n",
      "[19]\tvalid_0's multi_logloss: 0.229219\n",
      "[20]\tvalid_0's multi_logloss: 0.221301\n",
      "[21]\tvalid_0's multi_logloss: 0.214083\n",
      "[22]\tvalid_0's multi_logloss: 0.207653\n",
      "[23]\tvalid_0's multi_logloss: 0.201983\n",
      "[24]\tvalid_0's multi_logloss: 0.197761\n",
      "[25]\tvalid_0's multi_logloss: 0.193984\n",
      "[26]\tvalid_0's multi_logloss: 0.1897\n",
      "[27]\tvalid_0's multi_logloss: 0.186116\n",
      "[28]\tvalid_0's multi_logloss: 0.18305\n",
      "[29]\tvalid_0's multi_logloss: 0.180422\n",
      "[30]\tvalid_0's multi_logloss: 0.17777\n",
      "[31]\tvalid_0's multi_logloss: 0.175835\n",
      "[32]\tvalid_0's multi_logloss: 0.174204\n",
      "[33]\tvalid_0's multi_logloss: 0.173093\n",
      "[34]\tvalid_0's multi_logloss: 0.171474\n",
      "[35]\tvalid_0's multi_logloss: 0.170205\n",
      "[36]\tvalid_0's multi_logloss: 0.168879\n",
      "[37]\tvalid_0's multi_logloss: 0.168056\n",
      "[38]\tvalid_0's multi_logloss: 0.166899\n",
      "[39]\tvalid_0's multi_logloss: 0.165795\n",
      "[40]\tvalid_0's multi_logloss: 0.165039\n",
      "[41]\tvalid_0's multi_logloss: 0.164027\n",
      "[42]\tvalid_0's multi_logloss: 0.163052\n",
      "[43]\tvalid_0's multi_logloss: 0.16245\n",
      "[44]\tvalid_0's multi_logloss: 0.161679\n",
      "[45]\tvalid_0's multi_logloss: 0.16114\n",
      "[46]\tvalid_0's multi_logloss: 0.160358\n",
      "[47]\tvalid_0's multi_logloss: 0.159888\n",
      "[48]\tvalid_0's multi_logloss: 0.159531\n",
      "[49]\tvalid_0's multi_logloss: 0.159131\n",
      "[50]\tvalid_0's multi_logloss: 0.158878\n",
      "[51]\tvalid_0's multi_logloss: 0.158506\n",
      "[52]\tvalid_0's multi_logloss: 0.1582\n",
      "[53]\tvalid_0's multi_logloss: 0.157775\n",
      "[54]\tvalid_0's multi_logloss: 0.157487\n",
      "[55]\tvalid_0's multi_logloss: 0.157252\n",
      "[56]\tvalid_0's multi_logloss: 0.157149\n",
      "[57]\tvalid_0's multi_logloss: 0.15686\n",
      "[58]\tvalid_0's multi_logloss: 0.156692\n",
      "[59]\tvalid_0's multi_logloss: 0.156541\n",
      "[60]\tvalid_0's multi_logloss: 0.156404\n",
      "[61]\tvalid_0's multi_logloss: 0.156179\n",
      "[62]\tvalid_0's multi_logloss: 0.156026\n",
      "[63]\tvalid_0's multi_logloss: 0.155929\n",
      "[64]\tvalid_0's multi_logloss: 0.155773\n",
      "[65]\tvalid_0's multi_logloss: 0.155599\n",
      "[66]\tvalid_0's multi_logloss: 0.155567\n",
      "[67]\tvalid_0's multi_logloss: 0.155454\n",
      "[68]\tvalid_0's multi_logloss: 0.15536\n",
      "[69]\tvalid_0's multi_logloss: 0.155235\n",
      "[70]\tvalid_0's multi_logloss: 0.155123\n",
      "[71]\tvalid_0's multi_logloss: 0.154965\n",
      "[72]\tvalid_0's multi_logloss: 0.154864\n",
      "[73]\tvalid_0's multi_logloss: 0.154746\n",
      "[74]\tvalid_0's multi_logloss: 0.154681\n",
      "[75]\tvalid_0's multi_logloss: 0.154578\n",
      "[76]\tvalid_0's multi_logloss: 0.154481\n",
      "[77]\tvalid_0's multi_logloss: 0.154394\n",
      "[78]\tvalid_0's multi_logloss: 0.154284\n",
      "[79]\tvalid_0's multi_logloss: 0.154207\n",
      "[80]\tvalid_0's multi_logloss: 0.154171\n",
      "[81]\tvalid_0's multi_logloss: 0.154115\n",
      "[82]\tvalid_0's multi_logloss: 0.154082\n",
      "[83]\tvalid_0's multi_logloss: 0.153996\n",
      "[84]\tvalid_0's multi_logloss: 0.153964\n",
      "[85]\tvalid_0's multi_logloss: 0.153925\n",
      "[86]\tvalid_0's multi_logloss: 0.153889\n",
      "[87]\tvalid_0's multi_logloss: 0.153861\n",
      "[88]\tvalid_0's multi_logloss: 0.153827\n",
      "[89]\tvalid_0's multi_logloss: 0.153825\n",
      "[90]\tvalid_0's multi_logloss: 0.153808\n",
      "[91]\tvalid_0's multi_logloss: 0.15375\n",
      "[92]\tvalid_0's multi_logloss: 0.153736\n",
      "[93]\tvalid_0's multi_logloss: 0.153721\n",
      "[94]\tvalid_0's multi_logloss: 0.153713\n",
      "[95]\tvalid_0's multi_logloss: 0.153719\n",
      "[96]\tvalid_0's multi_logloss: 0.153661\n",
      "[97]\tvalid_0's multi_logloss: 0.153656\n",
      "[98]\tvalid_0's multi_logloss: 0.153696\n",
      "[99]\tvalid_0's multi_logloss: 0.153673\n",
      "[100]\tvalid_0's multi_logloss: 0.153641\n",
      "[101]\tvalid_0's multi_logloss: 0.153637\n",
      "[102]\tvalid_0's multi_logloss: 0.153689\n",
      "[103]\tvalid_0's multi_logloss: 0.153597\n",
      "[104]\tvalid_0's multi_logloss: 0.153602\n",
      "[105]\tvalid_0's multi_logloss: 0.153579\n",
      "[106]\tvalid_0's multi_logloss: 0.153588\n",
      "[107]\tvalid_0's multi_logloss: 0.153576\n",
      "[108]\tvalid_0's multi_logloss: 0.153557\n",
      "[109]\tvalid_0's multi_logloss: 0.153568\n",
      "[110]\tvalid_0's multi_logloss: 0.153575\n",
      "[111]\tvalid_0's multi_logloss: 0.153594\n",
      "[112]\tvalid_0's multi_logloss: 0.153589\n",
      "[113]\tvalid_0's multi_logloss: 0.153581\n",
      "[114]\tvalid_0's multi_logloss: 0.153611\n",
      "[115]\tvalid_0's multi_logloss: 0.153599\n",
      "[116]\tvalid_0's multi_logloss: 0.153626\n",
      "[117]\tvalid_0's multi_logloss: 0.153632\n",
      "[118]\tvalid_0's multi_logloss: 0.153621\n",
      "[119]\tvalid_0's multi_logloss: 0.153585\n",
      "[120]\tvalid_0's multi_logloss: 0.153552\n",
      "[121]\tvalid_0's multi_logloss: 0.153576\n",
      "[122]\tvalid_0's multi_logloss: 0.153579\n",
      "[123]\tvalid_0's multi_logloss: 0.153609\n",
      "[124]\tvalid_0's multi_logloss: 0.153609\n",
      "[125]\tvalid_0's multi_logloss: 0.153627\n",
      "[126]\tvalid_0's multi_logloss: 0.153622\n",
      "[127]\tvalid_0's multi_logloss: 0.153637\n",
      "[128]\tvalid_0's multi_logloss: 0.153638\n",
      "[129]\tvalid_0's multi_logloss: 0.153626\n",
      "[130]\tvalid_0's multi_logloss: 0.153635\n",
      "[131]\tvalid_0's multi_logloss: 0.153675\n",
      "[132]\tvalid_0's multi_logloss: 0.153661\n",
      "[133]\tvalid_0's multi_logloss: 0.15372\n",
      "[134]\tvalid_0's multi_logloss: 0.153735\n",
      "[135]\tvalid_0's multi_logloss: 0.153737\n",
      "[136]\tvalid_0's multi_logloss: 0.153765\n",
      "[137]\tvalid_0's multi_logloss: 0.153793\n",
      "[138]\tvalid_0's multi_logloss: 0.153759\n",
      "[139]\tvalid_0's multi_logloss: 0.153792\n",
      "[140]\tvalid_0's multi_logloss: 0.153786\n",
      "[141]\tvalid_0's multi_logloss: 0.153793\n",
      "[142]\tvalid_0's multi_logloss: 0.153818\n",
      "[143]\tvalid_0's multi_logloss: 0.15381\n",
      "[144]\tvalid_0's multi_logloss: 0.153831\n",
      "[145]\tvalid_0's multi_logloss: 0.153857\n",
      "[146]\tvalid_0's multi_logloss: 0.153846\n",
      "[147]\tvalid_0's multi_logloss: 0.153849\n",
      "[148]\tvalid_0's multi_logloss: 0.153864\n",
      "[149]\tvalid_0's multi_logloss: 0.153877\n",
      "[150]\tvalid_0's multi_logloss: 0.153862\n",
      "[151]\tvalid_0's multi_logloss: 0.153842\n",
      "[152]\tvalid_0's multi_logloss: 0.153848\n",
      "[153]\tvalid_0's multi_logloss: 0.1539\n",
      "[154]\tvalid_0's multi_logloss: 0.153914\n",
      "[155]\tvalid_0's multi_logloss: 0.153936\n",
      "[156]\tvalid_0's multi_logloss: 0.153977\n",
      "[157]\tvalid_0's multi_logloss: 0.154011\n",
      "[158]\tvalid_0's multi_logloss: 0.154004\n",
      "[159]\tvalid_0's multi_logloss: 0.154027\n",
      "[160]\tvalid_0's multi_logloss: 0.154016\n",
      "[161]\tvalid_0's multi_logloss: 0.154001\n",
      "[162]\tvalid_0's multi_logloss: 0.154002\n",
      "[163]\tvalid_0's multi_logloss: 0.154013\n",
      "[164]\tvalid_0's multi_logloss: 0.15404\n",
      "[165]\tvalid_0's multi_logloss: 0.15407\n",
      "[166]\tvalid_0's multi_logloss: 0.154114\n",
      "[167]\tvalid_0's multi_logloss: 0.154149\n",
      "[168]\tvalid_0's multi_logloss: 0.154201\n",
      "[169]\tvalid_0's multi_logloss: 0.154234\n",
      "[170]\tvalid_0's multi_logloss: 0.15422\n",
      "[171]\tvalid_0's multi_logloss: 0.154201\n",
      "[172]\tvalid_0's multi_logloss: 0.154217\n",
      "[173]\tvalid_0's multi_logloss: 0.154234\n",
      "[174]\tvalid_0's multi_logloss: 0.154238\n",
      "[175]\tvalid_0's multi_logloss: 0.154217\n",
      "[176]\tvalid_0's multi_logloss: 0.154239\n",
      "[177]\tvalid_0's multi_logloss: 0.154277\n",
      "[178]\tvalid_0's multi_logloss: 0.154288\n",
      "[179]\tvalid_0's multi_logloss: 0.154321\n",
      "[180]\tvalid_0's multi_logloss: 0.154361\n",
      "[181]\tvalid_0's multi_logloss: 0.154368\n",
      "[182]\tvalid_0's multi_logloss: 0.154381\n",
      "[183]\tvalid_0's multi_logloss: 0.154415\n",
      "[184]\tvalid_0's multi_logloss: 0.154434\n",
      "[185]\tvalid_0's multi_logloss: 0.154465\n",
      "[186]\tvalid_0's multi_logloss: 0.15451\n",
      "[187]\tvalid_0's multi_logloss: 0.154519\n",
      "[188]\tvalid_0's multi_logloss: 0.15449\n",
      "[189]\tvalid_0's multi_logloss: 0.154472\n",
      "[190]\tvalid_0's multi_logloss: 0.154488\n",
      "[191]\tvalid_0's multi_logloss: 0.154497\n",
      "[192]\tvalid_0's multi_logloss: 0.154539\n",
      "[193]\tvalid_0's multi_logloss: 0.154551\n",
      "[194]\tvalid_0's multi_logloss: 0.154558\n",
      "[195]\tvalid_0's multi_logloss: 0.154559\n",
      "[196]\tvalid_0's multi_logloss: 0.15459\n",
      "[197]\tvalid_0's multi_logloss: 0.154638\n",
      "[198]\tvalid_0's multi_logloss: 0.154662\n",
      "[199]\tvalid_0's multi_logloss: 0.154669\n",
      "[200]\tvalid_0's multi_logloss: 0.154686\n",
      "[201]\tvalid_0's multi_logloss: 0.154738\n",
      "[202]\tvalid_0's multi_logloss: 0.154716\n",
      "[203]\tvalid_0's multi_logloss: 0.15472\n",
      "[204]\tvalid_0's multi_logloss: 0.154737\n",
      "[205]\tvalid_0's multi_logloss: 0.154718\n",
      "[206]\tvalid_0's multi_logloss: 0.154712\n",
      "[207]\tvalid_0's multi_logloss: 0.154727\n",
      "[208]\tvalid_0's multi_logloss: 0.154759\n",
      "[209]\tvalid_0's multi_logloss: 0.154764\n",
      "[210]\tvalid_0's multi_logloss: 0.154747\n",
      "[211]\tvalid_0's multi_logloss: 0.154749\n",
      "[212]\tvalid_0's multi_logloss: 0.15477\n",
      "[213]\tvalid_0's multi_logloss: 0.154798\n",
      "[214]\tvalid_0's multi_logloss: 0.154809\n",
      "[215]\tvalid_0's multi_logloss: 0.154841\n",
      "[216]\tvalid_0's multi_logloss: 0.154878\n",
      "[217]\tvalid_0's multi_logloss: 0.154932\n",
      "[218]\tvalid_0's multi_logloss: 0.154931\n",
      "[219]\tvalid_0's multi_logloss: 0.154941\n",
      "[220]\tvalid_0's multi_logloss: 0.154969\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_logloss: 0.153552\n",
      "training model for CV #2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.848896\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.74357\n",
      "[3]\tvalid_0's multi_logloss: 0.65695\n",
      "[4]\tvalid_0's multi_logloss: 0.588677\n",
      "[5]\tvalid_0's multi_logloss: 0.534591\n",
      "[6]\tvalid_0's multi_logloss: 0.487088\n",
      "[7]\tvalid_0's multi_logloss: 0.450262\n",
      "[8]\tvalid_0's multi_logloss: 0.414141\n",
      "[9]\tvalid_0's multi_logloss: 0.381664\n",
      "[10]\tvalid_0's multi_logloss: 0.355732\n",
      "[11]\tvalid_0's multi_logloss: 0.334807\n",
      "[12]\tvalid_0's multi_logloss: 0.31679\n",
      "[13]\tvalid_0's multi_logloss: 0.299812\n",
      "[14]\tvalid_0's multi_logloss: 0.284657\n",
      "[15]\tvalid_0's multi_logloss: 0.272244\n",
      "[16]\tvalid_0's multi_logloss: 0.261027\n",
      "[17]\tvalid_0's multi_logloss: 0.250547\n",
      "[18]\tvalid_0's multi_logloss: 0.239848\n",
      "[19]\tvalid_0's multi_logloss: 0.231015\n",
      "[20]\tvalid_0's multi_logloss: 0.22313\n",
      "[21]\tvalid_0's multi_logloss: 0.21606\n",
      "[22]\tvalid_0's multi_logloss: 0.209481\n",
      "[23]\tvalid_0's multi_logloss: 0.203956\n",
      "[24]\tvalid_0's multi_logloss: 0.199681\n",
      "[25]\tvalid_0's multi_logloss: 0.195888\n",
      "[26]\tvalid_0's multi_logloss: 0.191671\n",
      "[27]\tvalid_0's multi_logloss: 0.188097\n",
      "[28]\tvalid_0's multi_logloss: 0.185081\n",
      "[29]\tvalid_0's multi_logloss: 0.182388\n",
      "[30]\tvalid_0's multi_logloss: 0.179857\n",
      "[31]\tvalid_0's multi_logloss: 0.177866\n",
      "[32]\tvalid_0's multi_logloss: 0.176179\n",
      "[33]\tvalid_0's multi_logloss: 0.174995\n",
      "[34]\tvalid_0's multi_logloss: 0.173505\n",
      "[35]\tvalid_0's multi_logloss: 0.172197\n",
      "[36]\tvalid_0's multi_logloss: 0.170908\n",
      "[37]\tvalid_0's multi_logloss: 0.170072\n",
      "[38]\tvalid_0's multi_logloss: 0.16894\n",
      "[39]\tvalid_0's multi_logloss: 0.167879\n",
      "[40]\tvalid_0's multi_logloss: 0.167086\n",
      "[41]\tvalid_0's multi_logloss: 0.166151\n",
      "[42]\tvalid_0's multi_logloss: 0.165221\n",
      "[43]\tvalid_0's multi_logloss: 0.164643\n",
      "[44]\tvalid_0's multi_logloss: 0.163814\n",
      "[45]\tvalid_0's multi_logloss: 0.16329\n",
      "[46]\tvalid_0's multi_logloss: 0.16262\n",
      "[47]\tvalid_0's multi_logloss: 0.162122\n",
      "[48]\tvalid_0's multi_logloss: 0.161666\n",
      "[49]\tvalid_0's multi_logloss: 0.161326\n",
      "[50]\tvalid_0's multi_logloss: 0.161089\n",
      "[51]\tvalid_0's multi_logloss: 0.160656\n",
      "[52]\tvalid_0's multi_logloss: 0.16029\n",
      "[53]\tvalid_0's multi_logloss: 0.159904\n",
      "[54]\tvalid_0's multi_logloss: 0.159578\n",
      "[55]\tvalid_0's multi_logloss: 0.159288\n",
      "[56]\tvalid_0's multi_logloss: 0.159155\n",
      "[57]\tvalid_0's multi_logloss: 0.158898\n",
      "[58]\tvalid_0's multi_logloss: 0.158733\n",
      "[59]\tvalid_0's multi_logloss: 0.158585\n",
      "[60]\tvalid_0's multi_logloss: 0.15838\n",
      "[61]\tvalid_0's multi_logloss: 0.158138\n",
      "[62]\tvalid_0's multi_logloss: 0.158037\n",
      "[63]\tvalid_0's multi_logloss: 0.157903\n",
      "[64]\tvalid_0's multi_logloss: 0.157741\n",
      "[65]\tvalid_0's multi_logloss: 0.157554\n",
      "[66]\tvalid_0's multi_logloss: 0.157501\n",
      "[67]\tvalid_0's multi_logloss: 0.157396\n",
      "[68]\tvalid_0's multi_logloss: 0.157283\n",
      "[69]\tvalid_0's multi_logloss: 0.15712\n",
      "[70]\tvalid_0's multi_logloss: 0.157094\n",
      "[71]\tvalid_0's multi_logloss: 0.156961\n",
      "[72]\tvalid_0's multi_logloss: 0.156907\n",
      "[73]\tvalid_0's multi_logloss: 0.156834\n",
      "[74]\tvalid_0's multi_logloss: 0.15672\n",
      "[75]\tvalid_0's multi_logloss: 0.156621\n",
      "[76]\tvalid_0's multi_logloss: 0.15648\n",
      "[77]\tvalid_0's multi_logloss: 0.156402\n",
      "[78]\tvalid_0's multi_logloss: 0.156357\n",
      "[79]\tvalid_0's multi_logloss: 0.156279\n",
      "[80]\tvalid_0's multi_logloss: 0.156257\n",
      "[81]\tvalid_0's multi_logloss: 0.156207\n",
      "[82]\tvalid_0's multi_logloss: 0.156169\n",
      "[83]\tvalid_0's multi_logloss: 0.156141\n",
      "[84]\tvalid_0's multi_logloss: 0.156142\n",
      "[85]\tvalid_0's multi_logloss: 0.15606\n",
      "[86]\tvalid_0's multi_logloss: 0.15602\n",
      "[87]\tvalid_0's multi_logloss: 0.155971\n",
      "[88]\tvalid_0's multi_logloss: 0.155893\n",
      "[89]\tvalid_0's multi_logloss: 0.15587\n",
      "[90]\tvalid_0's multi_logloss: 0.155869\n",
      "[91]\tvalid_0's multi_logloss: 0.155816\n",
      "[92]\tvalid_0's multi_logloss: 0.155742\n",
      "[93]\tvalid_0's multi_logloss: 0.155706\n",
      "[94]\tvalid_0's multi_logloss: 0.155694\n",
      "[95]\tvalid_0's multi_logloss: 0.155651\n",
      "[96]\tvalid_0's multi_logloss: 0.155646\n",
      "[97]\tvalid_0's multi_logloss: 0.155623\n",
      "[98]\tvalid_0's multi_logloss: 0.155641\n",
      "[99]\tvalid_0's multi_logloss: 0.155575\n",
      "[100]\tvalid_0's multi_logloss: 0.155581\n",
      "[101]\tvalid_0's multi_logloss: 0.155526\n",
      "[102]\tvalid_0's multi_logloss: 0.155483\n",
      "[103]\tvalid_0's multi_logloss: 0.155475\n",
      "[104]\tvalid_0's multi_logloss: 0.155419\n",
      "[105]\tvalid_0's multi_logloss: 0.155457\n",
      "[106]\tvalid_0's multi_logloss: 0.155355\n",
      "[107]\tvalid_0's multi_logloss: 0.155349\n",
      "[108]\tvalid_0's multi_logloss: 0.155327\n",
      "[109]\tvalid_0's multi_logloss: 0.155286\n",
      "[110]\tvalid_0's multi_logloss: 0.155293\n",
      "[111]\tvalid_0's multi_logloss: 0.155328\n",
      "[112]\tvalid_0's multi_logloss: 0.155295\n",
      "[113]\tvalid_0's multi_logloss: 0.155309\n",
      "[114]\tvalid_0's multi_logloss: 0.155348\n",
      "[115]\tvalid_0's multi_logloss: 0.155375\n",
      "[116]\tvalid_0's multi_logloss: 0.15539\n",
      "[117]\tvalid_0's multi_logloss: 0.155406\n",
      "[118]\tvalid_0's multi_logloss: 0.155385\n",
      "[119]\tvalid_0's multi_logloss: 0.155373\n",
      "[120]\tvalid_0's multi_logloss: 0.155413\n",
      "[121]\tvalid_0's multi_logloss: 0.155405\n",
      "[122]\tvalid_0's multi_logloss: 0.15544\n",
      "[123]\tvalid_0's multi_logloss: 0.155425\n",
      "[124]\tvalid_0's multi_logloss: 0.15542\n",
      "[125]\tvalid_0's multi_logloss: 0.155403\n",
      "[126]\tvalid_0's multi_logloss: 0.155385\n",
      "[127]\tvalid_0's multi_logloss: 0.155349\n",
      "[128]\tvalid_0's multi_logloss: 0.155346\n",
      "[129]\tvalid_0's multi_logloss: 0.155345\n",
      "[130]\tvalid_0's multi_logloss: 0.155343\n",
      "[131]\tvalid_0's multi_logloss: 0.15532\n",
      "[132]\tvalid_0's multi_logloss: 0.155349\n",
      "[133]\tvalid_0's multi_logloss: 0.155384\n",
      "[134]\tvalid_0's multi_logloss: 0.155409\n",
      "[135]\tvalid_0's multi_logloss: 0.155388\n",
      "[136]\tvalid_0's multi_logloss: 0.155357\n",
      "[137]\tvalid_0's multi_logloss: 0.155407\n",
      "[138]\tvalid_0's multi_logloss: 0.155378\n",
      "[139]\tvalid_0's multi_logloss: 0.155429\n",
      "[140]\tvalid_0's multi_logloss: 0.155413\n",
      "[141]\tvalid_0's multi_logloss: 0.155393\n",
      "[142]\tvalid_0's multi_logloss: 0.155431\n",
      "[143]\tvalid_0's multi_logloss: 0.155463\n",
      "[144]\tvalid_0's multi_logloss: 0.155515\n",
      "[145]\tvalid_0's multi_logloss: 0.155507\n",
      "[146]\tvalid_0's multi_logloss: 0.155532\n",
      "[147]\tvalid_0's multi_logloss: 0.155562\n",
      "[148]\tvalid_0's multi_logloss: 0.155585\n",
      "[149]\tvalid_0's multi_logloss: 0.1556\n",
      "[150]\tvalid_0's multi_logloss: 0.155567\n",
      "[151]\tvalid_0's multi_logloss: 0.155602\n",
      "[152]\tvalid_0's multi_logloss: 0.155605\n",
      "[153]\tvalid_0's multi_logloss: 0.155601\n",
      "[154]\tvalid_0's multi_logloss: 0.155616\n",
      "[155]\tvalid_0's multi_logloss: 0.155612\n",
      "[156]\tvalid_0's multi_logloss: 0.155604\n",
      "[157]\tvalid_0's multi_logloss: 0.155618\n",
      "[158]\tvalid_0's multi_logloss: 0.155634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159]\tvalid_0's multi_logloss: 0.155686\n",
      "[160]\tvalid_0's multi_logloss: 0.155736\n",
      "[161]\tvalid_0's multi_logloss: 0.155771\n",
      "[162]\tvalid_0's multi_logloss: 0.155769\n",
      "[163]\tvalid_0's multi_logloss: 0.155763\n",
      "[164]\tvalid_0's multi_logloss: 0.155777\n",
      "[165]\tvalid_0's multi_logloss: 0.155798\n",
      "[166]\tvalid_0's multi_logloss: 0.155843\n",
      "[167]\tvalid_0's multi_logloss: 0.155906\n",
      "[168]\tvalid_0's multi_logloss: 0.155911\n",
      "[169]\tvalid_0's multi_logloss: 0.155933\n",
      "[170]\tvalid_0's multi_logloss: 0.155956\n",
      "[171]\tvalid_0's multi_logloss: 0.155978\n",
      "[172]\tvalid_0's multi_logloss: 0.156054\n",
      "[173]\tvalid_0's multi_logloss: 0.156082\n",
      "[174]\tvalid_0's multi_logloss: 0.156077\n",
      "[175]\tvalid_0's multi_logloss: 0.156076\n",
      "[176]\tvalid_0's multi_logloss: 0.156088\n",
      "[177]\tvalid_0's multi_logloss: 0.156121\n",
      "[178]\tvalid_0's multi_logloss: 0.156163\n",
      "[179]\tvalid_0's multi_logloss: 0.156211\n",
      "[180]\tvalid_0's multi_logloss: 0.156199\n",
      "[181]\tvalid_0's multi_logloss: 0.156244\n",
      "[182]\tvalid_0's multi_logloss: 0.156275\n",
      "[183]\tvalid_0's multi_logloss: 0.15632\n",
      "[184]\tvalid_0's multi_logloss: 0.156342\n",
      "[185]\tvalid_0's multi_logloss: 0.156368\n",
      "[186]\tvalid_0's multi_logloss: 0.156406\n",
      "[187]\tvalid_0's multi_logloss: 0.15644\n",
      "[188]\tvalid_0's multi_logloss: 0.15646\n",
      "[189]\tvalid_0's multi_logloss: 0.156507\n",
      "[190]\tvalid_0's multi_logloss: 0.156539\n",
      "[191]\tvalid_0's multi_logloss: 0.156545\n",
      "[192]\tvalid_0's multi_logloss: 0.156524\n",
      "[193]\tvalid_0's multi_logloss: 0.156502\n",
      "[194]\tvalid_0's multi_logloss: 0.156536\n",
      "[195]\tvalid_0's multi_logloss: 0.156541\n",
      "[196]\tvalid_0's multi_logloss: 0.15656\n",
      "[197]\tvalid_0's multi_logloss: 0.156561\n",
      "[198]\tvalid_0's multi_logloss: 0.156576\n",
      "[199]\tvalid_0's multi_logloss: 0.156573\n",
      "[200]\tvalid_0's multi_logloss: 0.156577\n",
      "[201]\tvalid_0's multi_logloss: 0.156615\n",
      "[202]\tvalid_0's multi_logloss: 0.156616\n",
      "[203]\tvalid_0's multi_logloss: 0.156602\n",
      "[204]\tvalid_0's multi_logloss: 0.156569\n",
      "[205]\tvalid_0's multi_logloss: 0.156611\n",
      "[206]\tvalid_0's multi_logloss: 0.156597\n",
      "[207]\tvalid_0's multi_logloss: 0.156623\n",
      "[208]\tvalid_0's multi_logloss: 0.156646\n",
      "[209]\tvalid_0's multi_logloss: 0.156656\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.155286\n",
      "training model for CV #3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.848733\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.742979\n",
      "[3]\tvalid_0's multi_logloss: 0.656109\n",
      "[4]\tvalid_0's multi_logloss: 0.587391\n",
      "[5]\tvalid_0's multi_logloss: 0.533181\n",
      "[6]\tvalid_0's multi_logloss: 0.485437\n",
      "[7]\tvalid_0's multi_logloss: 0.448406\n",
      "[8]\tvalid_0's multi_logloss: 0.412225\n",
      "[9]\tvalid_0's multi_logloss: 0.3798\n",
      "[10]\tvalid_0's multi_logloss: 0.353741\n",
      "[11]\tvalid_0's multi_logloss: 0.332642\n",
      "[12]\tvalid_0's multi_logloss: 0.314679\n",
      "[13]\tvalid_0's multi_logloss: 0.297601\n",
      "[14]\tvalid_0's multi_logloss: 0.28247\n",
      "[15]\tvalid_0's multi_logloss: 0.270146\n",
      "[16]\tvalid_0's multi_logloss: 0.258903\n",
      "[17]\tvalid_0's multi_logloss: 0.248404\n",
      "[18]\tvalid_0's multi_logloss: 0.237835\n",
      "[19]\tvalid_0's multi_logloss: 0.228983\n",
      "[20]\tvalid_0's multi_logloss: 0.221087\n",
      "[21]\tvalid_0's multi_logloss: 0.213947\n",
      "[22]\tvalid_0's multi_logloss: 0.20734\n",
      "[23]\tvalid_0's multi_logloss: 0.201802\n",
      "[24]\tvalid_0's multi_logloss: 0.197506\n",
      "[25]\tvalid_0's multi_logloss: 0.193648\n",
      "[26]\tvalid_0's multi_logloss: 0.189326\n",
      "[27]\tvalid_0's multi_logloss: 0.185811\n",
      "[28]\tvalid_0's multi_logloss: 0.18283\n",
      "[29]\tvalid_0's multi_logloss: 0.180177\n",
      "[30]\tvalid_0's multi_logloss: 0.177653\n",
      "[31]\tvalid_0's multi_logloss: 0.175688\n",
      "[32]\tvalid_0's multi_logloss: 0.173858\n",
      "[33]\tvalid_0's multi_logloss: 0.172643\n",
      "[34]\tvalid_0's multi_logloss: 0.17105\n",
      "[35]\tvalid_0's multi_logloss: 0.16975\n",
      "[36]\tvalid_0's multi_logloss: 0.168388\n",
      "[37]\tvalid_0's multi_logloss: 0.167525\n",
      "[38]\tvalid_0's multi_logloss: 0.166433\n",
      "[39]\tvalid_0's multi_logloss: 0.165413\n",
      "[40]\tvalid_0's multi_logloss: 0.164589\n",
      "[41]\tvalid_0's multi_logloss: 0.163602\n",
      "[42]\tvalid_0's multi_logloss: 0.162726\n",
      "[43]\tvalid_0's multi_logloss: 0.162099\n",
      "[44]\tvalid_0's multi_logloss: 0.161279\n",
      "[45]\tvalid_0's multi_logloss: 0.160687\n",
      "[46]\tvalid_0's multi_logloss: 0.159918\n",
      "[47]\tvalid_0's multi_logloss: 0.159428\n",
      "[48]\tvalid_0's multi_logloss: 0.158912\n",
      "[49]\tvalid_0's multi_logloss: 0.158514\n",
      "[50]\tvalid_0's multi_logloss: 0.158324\n",
      "[51]\tvalid_0's multi_logloss: 0.157871\n",
      "[52]\tvalid_0's multi_logloss: 0.157544\n",
      "[53]\tvalid_0's multi_logloss: 0.157132\n",
      "[54]\tvalid_0's multi_logloss: 0.156884\n",
      "[55]\tvalid_0's multi_logloss: 0.156724\n",
      "[56]\tvalid_0's multi_logloss: 0.156609\n",
      "[57]\tvalid_0's multi_logloss: 0.156359\n",
      "[58]\tvalid_0's multi_logloss: 0.156129\n",
      "[59]\tvalid_0's multi_logloss: 0.155921\n",
      "[60]\tvalid_0's multi_logloss: 0.155682\n",
      "[61]\tvalid_0's multi_logloss: 0.155453\n",
      "[62]\tvalid_0's multi_logloss: 0.155402\n",
      "[63]\tvalid_0's multi_logloss: 0.155357\n",
      "[64]\tvalid_0's multi_logloss: 0.155119\n",
      "[65]\tvalid_0's multi_logloss: 0.154966\n",
      "[66]\tvalid_0's multi_logloss: 0.154949\n",
      "[67]\tvalid_0's multi_logloss: 0.154886\n",
      "[68]\tvalid_0's multi_logloss: 0.154843\n",
      "[69]\tvalid_0's multi_logloss: 0.154696\n",
      "[70]\tvalid_0's multi_logloss: 0.154648\n",
      "[71]\tvalid_0's multi_logloss: 0.154551\n",
      "[72]\tvalid_0's multi_logloss: 0.154485\n",
      "[73]\tvalid_0's multi_logloss: 0.154345\n",
      "[74]\tvalid_0's multi_logloss: 0.154218\n",
      "[75]\tvalid_0's multi_logloss: 0.15416\n",
      "[76]\tvalid_0's multi_logloss: 0.154082\n",
      "[77]\tvalid_0's multi_logloss: 0.154009\n",
      "[78]\tvalid_0's multi_logloss: 0.153886\n",
      "[79]\tvalid_0's multi_logloss: 0.153815\n",
      "[80]\tvalid_0's multi_logloss: 0.153791\n",
      "[81]\tvalid_0's multi_logloss: 0.153706\n",
      "[82]\tvalid_0's multi_logloss: 0.153644\n",
      "[83]\tvalid_0's multi_logloss: 0.153572\n",
      "[84]\tvalid_0's multi_logloss: 0.153548\n",
      "[85]\tvalid_0's multi_logloss: 0.15347\n",
      "[86]\tvalid_0's multi_logloss: 0.153376\n",
      "[87]\tvalid_0's multi_logloss: 0.153287\n",
      "[88]\tvalid_0's multi_logloss: 0.153243\n",
      "[89]\tvalid_0's multi_logloss: 0.153218\n",
      "[90]\tvalid_0's multi_logloss: 0.153118\n",
      "[91]\tvalid_0's multi_logloss: 0.153041\n",
      "[92]\tvalid_0's multi_logloss: 0.153017\n",
      "[93]\tvalid_0's multi_logloss: 0.153014\n",
      "[94]\tvalid_0's multi_logloss: 0.152985\n",
      "[95]\tvalid_0's multi_logloss: 0.152975\n",
      "[96]\tvalid_0's multi_logloss: 0.153025\n",
      "[97]\tvalid_0's multi_logloss: 0.153025\n",
      "[98]\tvalid_0's multi_logloss: 0.153019\n",
      "[99]\tvalid_0's multi_logloss: 0.153008\n",
      "[100]\tvalid_0's multi_logloss: 0.152999\n",
      "[101]\tvalid_0's multi_logloss: 0.152995\n",
      "[102]\tvalid_0's multi_logloss: 0.152952\n",
      "[103]\tvalid_0's multi_logloss: 0.152973\n",
      "[104]\tvalid_0's multi_logloss: 0.152957\n",
      "[105]\tvalid_0's multi_logloss: 0.152943\n",
      "[106]\tvalid_0's multi_logloss: 0.152906\n",
      "[107]\tvalid_0's multi_logloss: 0.152856\n",
      "[108]\tvalid_0's multi_logloss: 0.152863\n",
      "[109]\tvalid_0's multi_logloss: 0.152837\n",
      "[110]\tvalid_0's multi_logloss: 0.152902\n",
      "[111]\tvalid_0's multi_logloss: 0.152902\n",
      "[112]\tvalid_0's multi_logloss: 0.152916\n",
      "[113]\tvalid_0's multi_logloss: 0.152916\n",
      "[114]\tvalid_0's multi_logloss: 0.152927\n",
      "[115]\tvalid_0's multi_logloss: 0.152846\n",
      "[116]\tvalid_0's multi_logloss: 0.152789\n",
      "[117]\tvalid_0's multi_logloss: 0.15277\n",
      "[118]\tvalid_0's multi_logloss: 0.152733\n",
      "[119]\tvalid_0's multi_logloss: 0.152757\n",
      "[120]\tvalid_0's multi_logloss: 0.152769\n",
      "[121]\tvalid_0's multi_logloss: 0.152711\n",
      "[122]\tvalid_0's multi_logloss: 0.15272\n",
      "[123]\tvalid_0's multi_logloss: 0.152712\n",
      "[124]\tvalid_0's multi_logloss: 0.152742\n",
      "[125]\tvalid_0's multi_logloss: 0.152734\n",
      "[126]\tvalid_0's multi_logloss: 0.15273\n",
      "[127]\tvalid_0's multi_logloss: 0.152756\n",
      "[128]\tvalid_0's multi_logloss: 0.152746\n",
      "[129]\tvalid_0's multi_logloss: 0.152744\n",
      "[130]\tvalid_0's multi_logloss: 0.152752\n",
      "[131]\tvalid_0's multi_logloss: 0.15278\n",
      "[132]\tvalid_0's multi_logloss: 0.152771\n",
      "[133]\tvalid_0's multi_logloss: 0.152784\n",
      "[134]\tvalid_0's multi_logloss: 0.152778\n",
      "[135]\tvalid_0's multi_logloss: 0.15279\n",
      "[136]\tvalid_0's multi_logloss: 0.15276\n",
      "[137]\tvalid_0's multi_logloss: 0.152808\n",
      "[138]\tvalid_0's multi_logloss: 0.152831\n",
      "[139]\tvalid_0's multi_logloss: 0.152852\n",
      "[140]\tvalid_0's multi_logloss: 0.152839\n",
      "[141]\tvalid_0's multi_logloss: 0.152816\n",
      "[142]\tvalid_0's multi_logloss: 0.152808\n",
      "[143]\tvalid_0's multi_logloss: 0.152845\n",
      "[144]\tvalid_0's multi_logloss: 0.152881\n",
      "[145]\tvalid_0's multi_logloss: 0.152889\n",
      "[146]\tvalid_0's multi_logloss: 0.152899\n",
      "[147]\tvalid_0's multi_logloss: 0.152915\n",
      "[148]\tvalid_0's multi_logloss: 0.152903\n",
      "[149]\tvalid_0's multi_logloss: 0.152866\n",
      "[150]\tvalid_0's multi_logloss: 0.152911\n",
      "[151]\tvalid_0's multi_logloss: 0.152916\n",
      "[152]\tvalid_0's multi_logloss: 0.152991\n",
      "[153]\tvalid_0's multi_logloss: 0.152975\n",
      "[154]\tvalid_0's multi_logloss: 0.152945\n",
      "[155]\tvalid_0's multi_logloss: 0.152969\n",
      "[156]\tvalid_0's multi_logloss: 0.153027\n",
      "[157]\tvalid_0's multi_logloss: 0.153016\n",
      "[158]\tvalid_0's multi_logloss: 0.153061\n",
      "[159]\tvalid_0's multi_logloss: 0.153048\n",
      "[160]\tvalid_0's multi_logloss: 0.153049\n",
      "[161]\tvalid_0's multi_logloss: 0.153019\n",
      "[162]\tvalid_0's multi_logloss: 0.152973\n",
      "[163]\tvalid_0's multi_logloss: 0.152982\n",
      "[164]\tvalid_0's multi_logloss: 0.152949\n",
      "[165]\tvalid_0's multi_logloss: 0.152978\n",
      "[166]\tvalid_0's multi_logloss: 0.153032\n",
      "[167]\tvalid_0's multi_logloss: 0.153026\n",
      "[168]\tvalid_0's multi_logloss: 0.153053\n",
      "[169]\tvalid_0's multi_logloss: 0.153082\n",
      "[170]\tvalid_0's multi_logloss: 0.153026\n",
      "[171]\tvalid_0's multi_logloss: 0.153017\n",
      "[172]\tvalid_0's multi_logloss: 0.153067\n",
      "[173]\tvalid_0's multi_logloss: 0.153112\n",
      "[174]\tvalid_0's multi_logloss: 0.153141\n",
      "[175]\tvalid_0's multi_logloss: 0.153194\n",
      "[176]\tvalid_0's multi_logloss: 0.153236\n",
      "[177]\tvalid_0's multi_logloss: 0.153218\n",
      "[178]\tvalid_0's multi_logloss: 0.153198\n",
      "[179]\tvalid_0's multi_logloss: 0.153269\n",
      "[180]\tvalid_0's multi_logloss: 0.153237\n",
      "[181]\tvalid_0's multi_logloss: 0.153219\n",
      "[182]\tvalid_0's multi_logloss: 0.153258\n",
      "[183]\tvalid_0's multi_logloss: 0.153274\n",
      "[184]\tvalid_0's multi_logloss: 0.153318\n",
      "[185]\tvalid_0's multi_logloss: 0.153314\n",
      "[186]\tvalid_0's multi_logloss: 0.153331\n",
      "[187]\tvalid_0's multi_logloss: 0.153358\n",
      "[188]\tvalid_0's multi_logloss: 0.153414\n",
      "[189]\tvalid_0's multi_logloss: 0.153478\n",
      "[190]\tvalid_0's multi_logloss: 0.153517\n",
      "[191]\tvalid_0's multi_logloss: 0.153525\n",
      "[192]\tvalid_0's multi_logloss: 0.153545\n",
      "[193]\tvalid_0's multi_logloss: 0.153577\n",
      "[194]\tvalid_0's multi_logloss: 0.153621\n",
      "[195]\tvalid_0's multi_logloss: 0.153691\n",
      "[196]\tvalid_0's multi_logloss: 0.1537\n",
      "[197]\tvalid_0's multi_logloss: 0.153702\n",
      "[198]\tvalid_0's multi_logloss: 0.153699\n",
      "[199]\tvalid_0's multi_logloss: 0.153777\n",
      "[200]\tvalid_0's multi_logloss: 0.153803\n",
      "[201]\tvalid_0's multi_logloss: 0.153802\n",
      "[202]\tvalid_0's multi_logloss: 0.153817\n",
      "[203]\tvalid_0's multi_logloss: 0.153803\n",
      "[204]\tvalid_0's multi_logloss: 0.153823\n",
      "[205]\tvalid_0's multi_logloss: 0.153851\n",
      "[206]\tvalid_0's multi_logloss: 0.153844\n",
      "[207]\tvalid_0's multi_logloss: 0.153862\n",
      "[208]\tvalid_0's multi_logloss: 0.15388\n",
      "[209]\tvalid_0's multi_logloss: 0.153876\n",
      "[210]\tvalid_0's multi_logloss: 0.153868\n",
      "[211]\tvalid_0's multi_logloss: 0.153888\n",
      "[212]\tvalid_0's multi_logloss: 0.153889\n",
      "[213]\tvalid_0's multi_logloss: 0.153878\n",
      "[214]\tvalid_0's multi_logloss: 0.153895\n",
      "[215]\tvalid_0's multi_logloss: 0.153914\n",
      "[216]\tvalid_0's multi_logloss: 0.153992\n",
      "[217]\tvalid_0's multi_logloss: 0.154023\n",
      "[218]\tvalid_0's multi_logloss: 0.153964\n",
      "[219]\tvalid_0's multi_logloss: 0.153987\n",
      "[220]\tvalid_0's multi_logloss: 0.154025\n",
      "[221]\tvalid_0's multi_logloss: 0.154051\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.152711\n",
      "training model for CV #4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.849939\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.745258\n",
      "[3]\tvalid_0's multi_logloss: 0.65909\n",
      "[4]\tvalid_0's multi_logloss: 0.591073\n",
      "[5]\tvalid_0's multi_logloss: 0.537302\n",
      "[6]\tvalid_0's multi_logloss: 0.489879\n",
      "[7]\tvalid_0's multi_logloss: 0.453165\n",
      "[8]\tvalid_0's multi_logloss: 0.41718\n",
      "[9]\tvalid_0's multi_logloss: 0.384697\n",
      "[10]\tvalid_0's multi_logloss: 0.358641\n",
      "[11]\tvalid_0's multi_logloss: 0.337908\n",
      "[12]\tvalid_0's multi_logloss: 0.319977\n",
      "[13]\tvalid_0's multi_logloss: 0.302896\n",
      "[14]\tvalid_0's multi_logloss: 0.2879\n",
      "[15]\tvalid_0's multi_logloss: 0.275626\n",
      "[16]\tvalid_0's multi_logloss: 0.264387\n",
      "[17]\tvalid_0's multi_logloss: 0.253846\n",
      "[18]\tvalid_0's multi_logloss: 0.243206\n",
      "[19]\tvalid_0's multi_logloss: 0.234275\n",
      "[20]\tvalid_0's multi_logloss: 0.22655\n",
      "[21]\tvalid_0's multi_logloss: 0.219348\n",
      "[22]\tvalid_0's multi_logloss: 0.212781\n",
      "[23]\tvalid_0's multi_logloss: 0.207116\n",
      "[24]\tvalid_0's multi_logloss: 0.202834\n",
      "[25]\tvalid_0's multi_logloss: 0.199067\n",
      "[26]\tvalid_0's multi_logloss: 0.194825\n",
      "[27]\tvalid_0's multi_logloss: 0.191244\n",
      "[28]\tvalid_0's multi_logloss: 0.187989\n",
      "[29]\tvalid_0's multi_logloss: 0.185385\n",
      "[30]\tvalid_0's multi_logloss: 0.182839\n",
      "[31]\tvalid_0's multi_logloss: 0.180877\n",
      "[32]\tvalid_0's multi_logloss: 0.179157\n",
      "[33]\tvalid_0's multi_logloss: 0.177943\n",
      "[34]\tvalid_0's multi_logloss: 0.176392\n",
      "[35]\tvalid_0's multi_logloss: 0.175183\n",
      "[36]\tvalid_0's multi_logloss: 0.173773\n",
      "[37]\tvalid_0's multi_logloss: 0.172899\n",
      "[38]\tvalid_0's multi_logloss: 0.171847\n",
      "[39]\tvalid_0's multi_logloss: 0.170829\n",
      "[40]\tvalid_0's multi_logloss: 0.170073\n",
      "[41]\tvalid_0's multi_logloss: 0.169101\n",
      "[42]\tvalid_0's multi_logloss: 0.168211\n",
      "[43]\tvalid_0's multi_logloss: 0.167624\n",
      "[44]\tvalid_0's multi_logloss: 0.166789\n",
      "[45]\tvalid_0's multi_logloss: 0.166237\n",
      "[46]\tvalid_0's multi_logloss: 0.165562\n",
      "[47]\tvalid_0's multi_logloss: 0.165082\n",
      "[48]\tvalid_0's multi_logloss: 0.164675\n",
      "[49]\tvalid_0's multi_logloss: 0.164236\n",
      "[50]\tvalid_0's multi_logloss: 0.163958\n",
      "[51]\tvalid_0's multi_logloss: 0.163572\n",
      "[52]\tvalid_0's multi_logloss: 0.163203\n",
      "[53]\tvalid_0's multi_logloss: 0.162706\n",
      "[54]\tvalid_0's multi_logloss: 0.162434\n",
      "[55]\tvalid_0's multi_logloss: 0.162186\n",
      "[56]\tvalid_0's multi_logloss: 0.162059\n",
      "[57]\tvalid_0's multi_logloss: 0.161822\n",
      "[58]\tvalid_0's multi_logloss: 0.161615\n",
      "[59]\tvalid_0's multi_logloss: 0.161464\n",
      "[60]\tvalid_0's multi_logloss: 0.161351\n",
      "[61]\tvalid_0's multi_logloss: 0.161057\n",
      "[62]\tvalid_0's multi_logloss: 0.160842\n",
      "[63]\tvalid_0's multi_logloss: 0.160775\n",
      "[64]\tvalid_0's multi_logloss: 0.160584\n",
      "[65]\tvalid_0's multi_logloss: 0.160481\n",
      "[66]\tvalid_0's multi_logloss: 0.160419\n",
      "[67]\tvalid_0's multi_logloss: 0.160372\n",
      "[68]\tvalid_0's multi_logloss: 0.160286\n",
      "[69]\tvalid_0's multi_logloss: 0.160095\n",
      "[70]\tvalid_0's multi_logloss: 0.160019\n",
      "[71]\tvalid_0's multi_logloss: 0.159943\n",
      "[72]\tvalid_0's multi_logloss: 0.159848\n",
      "[73]\tvalid_0's multi_logloss: 0.159779\n",
      "[74]\tvalid_0's multi_logloss: 0.15967\n",
      "[75]\tvalid_0's multi_logloss: 0.159577\n",
      "[76]\tvalid_0's multi_logloss: 0.159413\n",
      "[77]\tvalid_0's multi_logloss: 0.159317\n",
      "[78]\tvalid_0's multi_logloss: 0.159263\n",
      "[79]\tvalid_0's multi_logloss: 0.15922\n",
      "[80]\tvalid_0's multi_logloss: 0.159101\n",
      "[81]\tvalid_0's multi_logloss: 0.159029\n",
      "[82]\tvalid_0's multi_logloss: 0.158949\n",
      "[83]\tvalid_0's multi_logloss: 0.158875\n",
      "[84]\tvalid_0's multi_logloss: 0.158822\n",
      "[85]\tvalid_0's multi_logloss: 0.158796\n",
      "[86]\tvalid_0's multi_logloss: 0.15879\n",
      "[87]\tvalid_0's multi_logloss: 0.158716\n",
      "[88]\tvalid_0's multi_logloss: 0.158657\n",
      "[89]\tvalid_0's multi_logloss: 0.158617\n",
      "[90]\tvalid_0's multi_logloss: 0.158634\n",
      "[91]\tvalid_0's multi_logloss: 0.15861\n",
      "[92]\tvalid_0's multi_logloss: 0.158647\n",
      "[93]\tvalid_0's multi_logloss: 0.158608\n",
      "[94]\tvalid_0's multi_logloss: 0.158591\n",
      "[95]\tvalid_0's multi_logloss: 0.158573\n",
      "[96]\tvalid_0's multi_logloss: 0.158529\n",
      "[97]\tvalid_0's multi_logloss: 0.158529\n",
      "[98]\tvalid_0's multi_logloss: 0.158525\n",
      "[99]\tvalid_0's multi_logloss: 0.158451\n",
      "[100]\tvalid_0's multi_logloss: 0.158439\n",
      "[101]\tvalid_0's multi_logloss: 0.158427\n",
      "[102]\tvalid_0's multi_logloss: 0.158448\n",
      "[103]\tvalid_0's multi_logloss: 0.158438\n",
      "[104]\tvalid_0's multi_logloss: 0.158407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105]\tvalid_0's multi_logloss: 0.158386\n",
      "[106]\tvalid_0's multi_logloss: 0.158331\n",
      "[107]\tvalid_0's multi_logloss: 0.158384\n",
      "[108]\tvalid_0's multi_logloss: 0.158378\n",
      "[109]\tvalid_0's multi_logloss: 0.158422\n",
      "[110]\tvalid_0's multi_logloss: 0.158445\n",
      "[111]\tvalid_0's multi_logloss: 0.158444\n",
      "[112]\tvalid_0's multi_logloss: 0.158472\n",
      "[113]\tvalid_0's multi_logloss: 0.158473\n",
      "[114]\tvalid_0's multi_logloss: 0.158447\n",
      "[115]\tvalid_0's multi_logloss: 0.158429\n",
      "[116]\tvalid_0's multi_logloss: 0.1584\n",
      "[117]\tvalid_0's multi_logloss: 0.158419\n",
      "[118]\tvalid_0's multi_logloss: 0.158455\n",
      "[119]\tvalid_0's multi_logloss: 0.158477\n",
      "[120]\tvalid_0's multi_logloss: 0.158497\n",
      "[121]\tvalid_0's multi_logloss: 0.158496\n",
      "[122]\tvalid_0's multi_logloss: 0.158512\n",
      "[123]\tvalid_0's multi_logloss: 0.158525\n",
      "[124]\tvalid_0's multi_logloss: 0.158514\n",
      "[125]\tvalid_0's multi_logloss: 0.158504\n",
      "[126]\tvalid_0's multi_logloss: 0.158549\n",
      "[127]\tvalid_0's multi_logloss: 0.158633\n",
      "[128]\tvalid_0's multi_logloss: 0.15863\n",
      "[129]\tvalid_0's multi_logloss: 0.158691\n",
      "[130]\tvalid_0's multi_logloss: 0.158687\n",
      "[131]\tvalid_0's multi_logloss: 0.15872\n",
      "[132]\tvalid_0's multi_logloss: 0.15876\n",
      "[133]\tvalid_0's multi_logloss: 0.158765\n",
      "[134]\tvalid_0's multi_logloss: 0.158726\n",
      "[135]\tvalid_0's multi_logloss: 0.158703\n",
      "[136]\tvalid_0's multi_logloss: 0.158749\n",
      "[137]\tvalid_0's multi_logloss: 0.158732\n",
      "[138]\tvalid_0's multi_logloss: 0.158776\n",
      "[139]\tvalid_0's multi_logloss: 0.158796\n",
      "[140]\tvalid_0's multi_logloss: 0.158791\n",
      "[141]\tvalid_0's multi_logloss: 0.158816\n",
      "[142]\tvalid_0's multi_logloss: 0.158886\n",
      "[143]\tvalid_0's multi_logloss: 0.158884\n",
      "[144]\tvalid_0's multi_logloss: 0.158912\n",
      "[145]\tvalid_0's multi_logloss: 0.159006\n",
      "[146]\tvalid_0's multi_logloss: 0.159055\n",
      "[147]\tvalid_0's multi_logloss: 0.159063\n",
      "[148]\tvalid_0's multi_logloss: 0.159071\n",
      "[149]\tvalid_0's multi_logloss: 0.159121\n",
      "[150]\tvalid_0's multi_logloss: 0.159184\n",
      "[151]\tvalid_0's multi_logloss: 0.159219\n",
      "[152]\tvalid_0's multi_logloss: 0.159245\n",
      "[153]\tvalid_0's multi_logloss: 0.159253\n",
      "[154]\tvalid_0's multi_logloss: 0.159298\n",
      "[155]\tvalid_0's multi_logloss: 0.159318\n",
      "[156]\tvalid_0's multi_logloss: 0.159332\n",
      "[157]\tvalid_0's multi_logloss: 0.159346\n",
      "[158]\tvalid_0's multi_logloss: 0.159342\n",
      "[159]\tvalid_0's multi_logloss: 0.159344\n",
      "[160]\tvalid_0's multi_logloss: 0.159365\n",
      "[161]\tvalid_0's multi_logloss: 0.159397\n",
      "[162]\tvalid_0's multi_logloss: 0.159448\n",
      "[163]\tvalid_0's multi_logloss: 0.159514\n",
      "[164]\tvalid_0's multi_logloss: 0.159536\n",
      "[165]\tvalid_0's multi_logloss: 0.159516\n",
      "[166]\tvalid_0's multi_logloss: 0.159533\n",
      "[167]\tvalid_0's multi_logloss: 0.159557\n",
      "[168]\tvalid_0's multi_logloss: 0.15958\n",
      "[169]\tvalid_0's multi_logloss: 0.159559\n",
      "[170]\tvalid_0's multi_logloss: 0.159577\n",
      "[171]\tvalid_0's multi_logloss: 0.159604\n",
      "[172]\tvalid_0's multi_logloss: 0.159608\n",
      "[173]\tvalid_0's multi_logloss: 0.159648\n",
      "[174]\tvalid_0's multi_logloss: 0.159644\n",
      "[175]\tvalid_0's multi_logloss: 0.15966\n",
      "[176]\tvalid_0's multi_logloss: 0.159703\n",
      "[177]\tvalid_0's multi_logloss: 0.159752\n",
      "[178]\tvalid_0's multi_logloss: 0.159782\n",
      "[179]\tvalid_0's multi_logloss: 0.159801\n",
      "[180]\tvalid_0's multi_logloss: 0.159778\n",
      "[181]\tvalid_0's multi_logloss: 0.159811\n",
      "[182]\tvalid_0's multi_logloss: 0.1598\n",
      "[183]\tvalid_0's multi_logloss: 0.159801\n",
      "[184]\tvalid_0's multi_logloss: 0.159793\n",
      "[185]\tvalid_0's multi_logloss: 0.159769\n",
      "[186]\tvalid_0's multi_logloss: 0.159741\n",
      "[187]\tvalid_0's multi_logloss: 0.159755\n",
      "[188]\tvalid_0's multi_logloss: 0.159745\n",
      "[189]\tvalid_0's multi_logloss: 0.159809\n",
      "[190]\tvalid_0's multi_logloss: 0.159802\n",
      "[191]\tvalid_0's multi_logloss: 0.159816\n",
      "[192]\tvalid_0's multi_logloss: 0.159873\n",
      "[193]\tvalid_0's multi_logloss: 0.159869\n",
      "[194]\tvalid_0's multi_logloss: 0.159852\n",
      "[195]\tvalid_0's multi_logloss: 0.159851\n",
      "[196]\tvalid_0's multi_logloss: 0.159895\n",
      "[197]\tvalid_0's multi_logloss: 0.159905\n",
      "[198]\tvalid_0's multi_logloss: 0.159923\n",
      "[199]\tvalid_0's multi_logloss: 0.159954\n",
      "[200]\tvalid_0's multi_logloss: 0.159994\n",
      "[201]\tvalid_0's multi_logloss: 0.160025\n",
      "[202]\tvalid_0's multi_logloss: 0.160069\n",
      "[203]\tvalid_0's multi_logloss: 0.160083\n",
      "[204]\tvalid_0's multi_logloss: 0.160139\n",
      "[205]\tvalid_0's multi_logloss: 0.160127\n",
      "[206]\tvalid_0's multi_logloss: 0.160122\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.158331\n",
      "training model for CV #5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.848567\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.743255\n",
      "[3]\tvalid_0's multi_logloss: 0.656519\n",
      "[4]\tvalid_0's multi_logloss: 0.588093\n",
      "[5]\tvalid_0's multi_logloss: 0.533932\n",
      "[6]\tvalid_0's multi_logloss: 0.486453\n",
      "[7]\tvalid_0's multi_logloss: 0.449638\n",
      "[8]\tvalid_0's multi_logloss: 0.413615\n",
      "[9]\tvalid_0's multi_logloss: 0.381148\n",
      "[10]\tvalid_0's multi_logloss: 0.355247\n",
      "[11]\tvalid_0's multi_logloss: 0.334266\n",
      "[12]\tvalid_0's multi_logloss: 0.31633\n",
      "[13]\tvalid_0's multi_logloss: 0.299184\n",
      "[14]\tvalid_0's multi_logloss: 0.284017\n",
      "[15]\tvalid_0's multi_logloss: 0.271647\n",
      "[16]\tvalid_0's multi_logloss: 0.260428\n",
      "[17]\tvalid_0's multi_logloss: 0.249909\n",
      "[18]\tvalid_0's multi_logloss: 0.239264\n",
      "[19]\tvalid_0's multi_logloss: 0.230334\n",
      "[20]\tvalid_0's multi_logloss: 0.222452\n",
      "[21]\tvalid_0's multi_logloss: 0.215289\n",
      "[22]\tvalid_0's multi_logloss: 0.208688\n",
      "[23]\tvalid_0's multi_logloss: 0.203136\n",
      "[24]\tvalid_0's multi_logloss: 0.198783\n",
      "[25]\tvalid_0's multi_logloss: 0.19497\n",
      "[26]\tvalid_0's multi_logloss: 0.190671\n",
      "[27]\tvalid_0's multi_logloss: 0.187171\n",
      "[28]\tvalid_0's multi_logloss: 0.184097\n",
      "[29]\tvalid_0's multi_logloss: 0.181318\n",
      "[30]\tvalid_0's multi_logloss: 0.17877\n",
      "[31]\tvalid_0's multi_logloss: 0.176853\n",
      "[32]\tvalid_0's multi_logloss: 0.175177\n",
      "[33]\tvalid_0's multi_logloss: 0.173978\n",
      "[34]\tvalid_0's multi_logloss: 0.172382\n",
      "[35]\tvalid_0's multi_logloss: 0.171131\n",
      "[36]\tvalid_0's multi_logloss: 0.169835\n",
      "[37]\tvalid_0's multi_logloss: 0.168941\n",
      "[38]\tvalid_0's multi_logloss: 0.167825\n",
      "[39]\tvalid_0's multi_logloss: 0.166764\n",
      "[40]\tvalid_0's multi_logloss: 0.165968\n",
      "[41]\tvalid_0's multi_logloss: 0.165002\n",
      "[42]\tvalid_0's multi_logloss: 0.164099\n",
      "[43]\tvalid_0's multi_logloss: 0.163541\n",
      "[44]\tvalid_0's multi_logloss: 0.162702\n",
      "[45]\tvalid_0's multi_logloss: 0.162216\n",
      "[46]\tvalid_0's multi_logloss: 0.161497\n",
      "[47]\tvalid_0's multi_logloss: 0.161085\n",
      "[48]\tvalid_0's multi_logloss: 0.16073\n",
      "[49]\tvalid_0's multi_logloss: 0.160405\n",
      "[50]\tvalid_0's multi_logloss: 0.160176\n",
      "[51]\tvalid_0's multi_logloss: 0.159763\n",
      "[52]\tvalid_0's multi_logloss: 0.159491\n",
      "[53]\tvalid_0's multi_logloss: 0.159125\n",
      "[54]\tvalid_0's multi_logloss: 0.15883\n",
      "[55]\tvalid_0's multi_logloss: 0.158588\n",
      "[56]\tvalid_0's multi_logloss: 0.158414\n",
      "[57]\tvalid_0's multi_logloss: 0.158142\n",
      "[58]\tvalid_0's multi_logloss: 0.157925\n",
      "[59]\tvalid_0's multi_logloss: 0.157731\n",
      "[60]\tvalid_0's multi_logloss: 0.157524\n",
      "[61]\tvalid_0's multi_logloss: 0.1573\n",
      "[62]\tvalid_0's multi_logloss: 0.157191\n",
      "[63]\tvalid_0's multi_logloss: 0.157132\n",
      "[64]\tvalid_0's multi_logloss: 0.156932\n",
      "[65]\tvalid_0's multi_logloss: 0.15679\n",
      "[66]\tvalid_0's multi_logloss: 0.156783\n",
      "[67]\tvalid_0's multi_logloss: 0.156631\n",
      "[68]\tvalid_0's multi_logloss: 0.156576\n",
      "[69]\tvalid_0's multi_logloss: 0.156433\n",
      "[70]\tvalid_0's multi_logloss: 0.156415\n",
      "[71]\tvalid_0's multi_logloss: 0.15632\n",
      "[72]\tvalid_0's multi_logloss: 0.156203\n",
      "[73]\tvalid_0's multi_logloss: 0.156113\n",
      "[74]\tvalid_0's multi_logloss: 0.156072\n",
      "[75]\tvalid_0's multi_logloss: 0.156036\n",
      "[76]\tvalid_0's multi_logloss: 0.155935\n",
      "[77]\tvalid_0's multi_logloss: 0.155861\n",
      "[78]\tvalid_0's multi_logloss: 0.155808\n",
      "[79]\tvalid_0's multi_logloss: 0.155832\n",
      "[80]\tvalid_0's multi_logloss: 0.155759\n",
      "[81]\tvalid_0's multi_logloss: 0.155754\n",
      "[82]\tvalid_0's multi_logloss: 0.15576\n",
      "[83]\tvalid_0's multi_logloss: 0.155645\n",
      "[84]\tvalid_0's multi_logloss: 0.155588\n",
      "[85]\tvalid_0's multi_logloss: 0.155572\n",
      "[86]\tvalid_0's multi_logloss: 0.155581\n",
      "[87]\tvalid_0's multi_logloss: 0.15553\n",
      "[88]\tvalid_0's multi_logloss: 0.155538\n",
      "[89]\tvalid_0's multi_logloss: 0.155563\n",
      "[90]\tvalid_0's multi_logloss: 0.15553\n",
      "[91]\tvalid_0's multi_logloss: 0.155495\n",
      "[92]\tvalid_0's multi_logloss: 0.155485\n",
      "[93]\tvalid_0's multi_logloss: 0.155566\n",
      "[94]\tvalid_0's multi_logloss: 0.155543\n",
      "[95]\tvalid_0's multi_logloss: 0.155526\n",
      "[96]\tvalid_0's multi_logloss: 0.155519\n",
      "[97]\tvalid_0's multi_logloss: 0.155554\n",
      "[98]\tvalid_0's multi_logloss: 0.155585\n",
      "[99]\tvalid_0's multi_logloss: 0.155591\n",
      "[100]\tvalid_0's multi_logloss: 0.155624\n",
      "[101]\tvalid_0's multi_logloss: 0.155662\n",
      "[102]\tvalid_0's multi_logloss: 0.15568\n",
      "[103]\tvalid_0's multi_logloss: 0.15568\n",
      "[104]\tvalid_0's multi_logloss: 0.155619\n",
      "[105]\tvalid_0's multi_logloss: 0.155667\n",
      "[106]\tvalid_0's multi_logloss: 0.155664\n",
      "[107]\tvalid_0's multi_logloss: 0.155659\n",
      "[108]\tvalid_0's multi_logloss: 0.155635\n",
      "[109]\tvalid_0's multi_logloss: 0.155613\n",
      "[110]\tvalid_0's multi_logloss: 0.155605\n",
      "[111]\tvalid_0's multi_logloss: 0.155603\n",
      "[112]\tvalid_0's multi_logloss: 0.155635\n",
      "[113]\tvalid_0's multi_logloss: 0.155604\n",
      "[114]\tvalid_0's multi_logloss: 0.155628\n",
      "[115]\tvalid_0's multi_logloss: 0.155613\n",
      "[116]\tvalid_0's multi_logloss: 0.155583\n",
      "[117]\tvalid_0's multi_logloss: 0.155631\n",
      "[118]\tvalid_0's multi_logloss: 0.155672\n",
      "[119]\tvalid_0's multi_logloss: 0.155759\n",
      "[120]\tvalid_0's multi_logloss: 0.155809\n",
      "[121]\tvalid_0's multi_logloss: 0.155795\n",
      "[122]\tvalid_0's multi_logloss: 0.155829\n",
      "[123]\tvalid_0's multi_logloss: 0.155787\n",
      "[124]\tvalid_0's multi_logloss: 0.155787\n",
      "[125]\tvalid_0's multi_logloss: 0.155821\n",
      "[126]\tvalid_0's multi_logloss: 0.155848\n",
      "[127]\tvalid_0's multi_logloss: 0.155885\n",
      "[128]\tvalid_0's multi_logloss: 0.155897\n",
      "[129]\tvalid_0's multi_logloss: 0.155932\n",
      "[130]\tvalid_0's multi_logloss: 0.15592\n",
      "[131]\tvalid_0's multi_logloss: 0.155937\n",
      "[132]\tvalid_0's multi_logloss: 0.155962\n",
      "[133]\tvalid_0's multi_logloss: 0.155988\n",
      "[134]\tvalid_0's multi_logloss: 0.155982\n",
      "[135]\tvalid_0's multi_logloss: 0.156027\n",
      "[136]\tvalid_0's multi_logloss: 0.156046\n",
      "[137]\tvalid_0's multi_logloss: 0.156047\n",
      "[138]\tvalid_0's multi_logloss: 0.156092\n",
      "[139]\tvalid_0's multi_logloss: 0.156126\n",
      "[140]\tvalid_0's multi_logloss: 0.156183\n",
      "[141]\tvalid_0's multi_logloss: 0.156192\n",
      "[142]\tvalid_0's multi_logloss: 0.156249\n",
      "[143]\tvalid_0's multi_logloss: 0.156226\n",
      "[144]\tvalid_0's multi_logloss: 0.156247\n",
      "[145]\tvalid_0's multi_logloss: 0.156273\n",
      "[146]\tvalid_0's multi_logloss: 0.156346\n",
      "[147]\tvalid_0's multi_logloss: 0.156375\n",
      "[148]\tvalid_0's multi_logloss: 0.156405\n",
      "[149]\tvalid_0's multi_logloss: 0.156362\n",
      "[150]\tvalid_0's multi_logloss: 0.156389\n",
      "[151]\tvalid_0's multi_logloss: 0.15642\n",
      "[152]\tvalid_0's multi_logloss: 0.156451\n",
      "[153]\tvalid_0's multi_logloss: 0.156464\n",
      "[154]\tvalid_0's multi_logloss: 0.156458\n",
      "[155]\tvalid_0's multi_logloss: 0.156499\n",
      "[156]\tvalid_0's multi_logloss: 0.156471\n",
      "[157]\tvalid_0's multi_logloss: 0.156493\n",
      "[158]\tvalid_0's multi_logloss: 0.15653\n",
      "[159]\tvalid_0's multi_logloss: 0.156557\n",
      "[160]\tvalid_0's multi_logloss: 0.156565\n",
      "[161]\tvalid_0's multi_logloss: 0.156616\n",
      "[162]\tvalid_0's multi_logloss: 0.156703\n",
      "[163]\tvalid_0's multi_logloss: 0.156767\n",
      "[164]\tvalid_0's multi_logloss: 0.156764\n",
      "[165]\tvalid_0's multi_logloss: 0.1568\n",
      "[166]\tvalid_0's multi_logloss: 0.156822\n",
      "[167]\tvalid_0's multi_logloss: 0.156883\n",
      "[168]\tvalid_0's multi_logloss: 0.156909\n",
      "[169]\tvalid_0's multi_logloss: 0.156976\n",
      "[170]\tvalid_0's multi_logloss: 0.157018\n",
      "[171]\tvalid_0's multi_logloss: 0.156993\n",
      "[172]\tvalid_0's multi_logloss: 0.157074\n",
      "[173]\tvalid_0's multi_logloss: 0.157072\n",
      "[174]\tvalid_0's multi_logloss: 0.157057\n",
      "[175]\tvalid_0's multi_logloss: 0.157077\n",
      "[176]\tvalid_0's multi_logloss: 0.157097\n",
      "[177]\tvalid_0's multi_logloss: 0.157126\n",
      "[178]\tvalid_0's multi_logloss: 0.157154\n",
      "[179]\tvalid_0's multi_logloss: 0.157175\n",
      "[180]\tvalid_0's multi_logloss: 0.157193\n",
      "[181]\tvalid_0's multi_logloss: 0.157186\n",
      "[182]\tvalid_0's multi_logloss: 0.15721\n",
      "[183]\tvalid_0's multi_logloss: 0.157265\n",
      "[184]\tvalid_0's multi_logloss: 0.157275\n",
      "[185]\tvalid_0's multi_logloss: 0.157306\n",
      "[186]\tvalid_0's multi_logloss: 0.157329\n",
      "[187]\tvalid_0's multi_logloss: 0.157324\n",
      "[188]\tvalid_0's multi_logloss: 0.157343\n",
      "[189]\tvalid_0's multi_logloss: 0.157312\n",
      "[190]\tvalid_0's multi_logloss: 0.157285\n",
      "[191]\tvalid_0's multi_logloss: 0.157333\n",
      "[192]\tvalid_0's multi_logloss: 0.157349\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's multi_logloss: 0.155485\n",
      "training model for CV #6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.849587\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.745046\n",
      "[3]\tvalid_0's multi_logloss: 0.658538\n",
      "[4]\tvalid_0's multi_logloss: 0.590185\n",
      "[5]\tvalid_0's multi_logloss: 0.536473\n",
      "[6]\tvalid_0's multi_logloss: 0.489114\n",
      "[7]\tvalid_0's multi_logloss: 0.45233\n",
      "[8]\tvalid_0's multi_logloss: 0.416277\n",
      "[9]\tvalid_0's multi_logloss: 0.38384\n",
      "[10]\tvalid_0's multi_logloss: 0.357973\n",
      "[11]\tvalid_0's multi_logloss: 0.337224\n",
      "[12]\tvalid_0's multi_logloss: 0.319379\n",
      "[13]\tvalid_0's multi_logloss: 0.302497\n",
      "[14]\tvalid_0's multi_logloss: 0.287429\n",
      "[15]\tvalid_0's multi_logloss: 0.275095\n",
      "[16]\tvalid_0's multi_logloss: 0.263952\n",
      "[17]\tvalid_0's multi_logloss: 0.253666\n",
      "[18]\tvalid_0's multi_logloss: 0.243007\n",
      "[19]\tvalid_0's multi_logloss: 0.23407\n",
      "[20]\tvalid_0's multi_logloss: 0.226226\n",
      "[21]\tvalid_0's multi_logloss: 0.218935\n",
      "[22]\tvalid_0's multi_logloss: 0.212411\n",
      "[23]\tvalid_0's multi_logloss: 0.206791\n",
      "[24]\tvalid_0's multi_logloss: 0.202501\n",
      "[25]\tvalid_0's multi_logloss: 0.198605\n",
      "[26]\tvalid_0's multi_logloss: 0.194375\n",
      "[27]\tvalid_0's multi_logloss: 0.190793\n",
      "[28]\tvalid_0's multi_logloss: 0.187685\n",
      "[29]\tvalid_0's multi_logloss: 0.184978\n",
      "[30]\tvalid_0's multi_logloss: 0.182339\n",
      "[31]\tvalid_0's multi_logloss: 0.180409\n",
      "[32]\tvalid_0's multi_logloss: 0.178748\n",
      "[33]\tvalid_0's multi_logloss: 0.177525\n",
      "[34]\tvalid_0's multi_logloss: 0.175966\n",
      "[35]\tvalid_0's multi_logloss: 0.174656\n",
      "[36]\tvalid_0's multi_logloss: 0.173295\n",
      "[37]\tvalid_0's multi_logloss: 0.172493\n",
      "[38]\tvalid_0's multi_logloss: 0.17144\n",
      "[39]\tvalid_0's multi_logloss: 0.170353\n",
      "[40]\tvalid_0's multi_logloss: 0.169636\n",
      "[41]\tvalid_0's multi_logloss: 0.168675\n",
      "[42]\tvalid_0's multi_logloss: 0.167768\n",
      "[43]\tvalid_0's multi_logloss: 0.167235\n",
      "[44]\tvalid_0's multi_logloss: 0.166451\n",
      "[45]\tvalid_0's multi_logloss: 0.165922\n",
      "[46]\tvalid_0's multi_logloss: 0.165253\n",
      "[47]\tvalid_0's multi_logloss: 0.164778\n",
      "[48]\tvalid_0's multi_logloss: 0.164402\n",
      "[49]\tvalid_0's multi_logloss: 0.163958\n",
      "[50]\tvalid_0's multi_logloss: 0.163726\n",
      "[51]\tvalid_0's multi_logloss: 0.163301\n",
      "[52]\tvalid_0's multi_logloss: 0.163\n",
      "[53]\tvalid_0's multi_logloss: 0.162545\n",
      "[54]\tvalid_0's multi_logloss: 0.162311\n",
      "[55]\tvalid_0's multi_logloss: 0.162046\n",
      "[56]\tvalid_0's multi_logloss: 0.161944\n",
      "[57]\tvalid_0's multi_logloss: 0.161693\n",
      "[58]\tvalid_0's multi_logloss: 0.161554\n",
      "[59]\tvalid_0's multi_logloss: 0.161503\n",
      "[60]\tvalid_0's multi_logloss: 0.161358\n",
      "[61]\tvalid_0's multi_logloss: 0.161094\n",
      "[62]\tvalid_0's multi_logloss: 0.16093\n",
      "[63]\tvalid_0's multi_logloss: 0.160866\n",
      "[64]\tvalid_0's multi_logloss: 0.160625\n",
      "[65]\tvalid_0's multi_logloss: 0.160418\n",
      "[66]\tvalid_0's multi_logloss: 0.160372\n",
      "[67]\tvalid_0's multi_logloss: 0.160331\n",
      "[68]\tvalid_0's multi_logloss: 0.160251\n",
      "[69]\tvalid_0's multi_logloss: 0.160073\n",
      "[70]\tvalid_0's multi_logloss: 0.15999\n",
      "[71]\tvalid_0's multi_logloss: 0.1599\n",
      "[72]\tvalid_0's multi_logloss: 0.159782\n",
      "[73]\tvalid_0's multi_logloss: 0.159674\n",
      "[74]\tvalid_0's multi_logloss: 0.159602\n",
      "[75]\tvalid_0's multi_logloss: 0.159553\n",
      "[76]\tvalid_0's multi_logloss: 0.159402\n",
      "[77]\tvalid_0's multi_logloss: 0.159317\n",
      "[78]\tvalid_0's multi_logloss: 0.159314\n",
      "[79]\tvalid_0's multi_logloss: 0.159226\n",
      "[80]\tvalid_0's multi_logloss: 0.159204\n",
      "[81]\tvalid_0's multi_logloss: 0.159193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82]\tvalid_0's multi_logloss: 0.159137\n",
      "[83]\tvalid_0's multi_logloss: 0.159095\n",
      "[84]\tvalid_0's multi_logloss: 0.159042\n",
      "[85]\tvalid_0's multi_logloss: 0.158971\n",
      "[86]\tvalid_0's multi_logloss: 0.158924\n",
      "[87]\tvalid_0's multi_logloss: 0.158881\n",
      "[88]\tvalid_0's multi_logloss: 0.158822\n",
      "[89]\tvalid_0's multi_logloss: 0.158806\n",
      "[90]\tvalid_0's multi_logloss: 0.158775\n",
      "[91]\tvalid_0's multi_logloss: 0.158739\n",
      "[92]\tvalid_0's multi_logloss: 0.158715\n",
      "[93]\tvalid_0's multi_logloss: 0.158717\n",
      "[94]\tvalid_0's multi_logloss: 0.158658\n",
      "[95]\tvalid_0's multi_logloss: 0.158627\n",
      "[96]\tvalid_0's multi_logloss: 0.158642\n",
      "[97]\tvalid_0's multi_logloss: 0.158649\n",
      "[98]\tvalid_0's multi_logloss: 0.158661\n",
      "[99]\tvalid_0's multi_logloss: 0.15871\n",
      "[100]\tvalid_0's multi_logloss: 0.158703\n",
      "[101]\tvalid_0's multi_logloss: 0.15869\n",
      "[102]\tvalid_0's multi_logloss: 0.158706\n",
      "[103]\tvalid_0's multi_logloss: 0.158705\n",
      "[104]\tvalid_0's multi_logloss: 0.158683\n",
      "[105]\tvalid_0's multi_logloss: 0.158682\n",
      "[106]\tvalid_0's multi_logloss: 0.158671\n",
      "[107]\tvalid_0's multi_logloss: 0.158689\n",
      "[108]\tvalid_0's multi_logloss: 0.158696\n",
      "[109]\tvalid_0's multi_logloss: 0.158706\n",
      "[110]\tvalid_0's multi_logloss: 0.158729\n",
      "[111]\tvalid_0's multi_logloss: 0.158708\n",
      "[112]\tvalid_0's multi_logloss: 0.158733\n",
      "[113]\tvalid_0's multi_logloss: 0.15873\n",
      "[114]\tvalid_0's multi_logloss: 0.158751\n",
      "[115]\tvalid_0's multi_logloss: 0.158758\n",
      "[116]\tvalid_0's multi_logloss: 0.158772\n",
      "[117]\tvalid_0's multi_logloss: 0.158803\n",
      "[118]\tvalid_0's multi_logloss: 0.158854\n",
      "[119]\tvalid_0's multi_logloss: 0.158815\n",
      "[120]\tvalid_0's multi_logloss: 0.158802\n",
      "[121]\tvalid_0's multi_logloss: 0.158797\n",
      "[122]\tvalid_0's multi_logloss: 0.158797\n",
      "[123]\tvalid_0's multi_logloss: 0.158847\n",
      "[124]\tvalid_0's multi_logloss: 0.15886\n",
      "[125]\tvalid_0's multi_logloss: 0.158849\n",
      "[126]\tvalid_0's multi_logloss: 0.158824\n",
      "[127]\tvalid_0's multi_logloss: 0.158849\n",
      "[128]\tvalid_0's multi_logloss: 0.158882\n",
      "[129]\tvalid_0's multi_logloss: 0.158885\n",
      "[130]\tvalid_0's multi_logloss: 0.158928\n",
      "[131]\tvalid_0's multi_logloss: 0.158933\n",
      "[132]\tvalid_0's multi_logloss: 0.158974\n",
      "[133]\tvalid_0's multi_logloss: 0.159036\n",
      "[134]\tvalid_0's multi_logloss: 0.159029\n",
      "[135]\tvalid_0's multi_logloss: 0.159047\n",
      "[136]\tvalid_0's multi_logloss: 0.159042\n",
      "[137]\tvalid_0's multi_logloss: 0.159039\n",
      "[138]\tvalid_0's multi_logloss: 0.159013\n",
      "[139]\tvalid_0's multi_logloss: 0.158991\n",
      "[140]\tvalid_0's multi_logloss: 0.159005\n",
      "[141]\tvalid_0's multi_logloss: 0.159081\n",
      "[142]\tvalid_0's multi_logloss: 0.159119\n",
      "[143]\tvalid_0's multi_logloss: 0.159113\n",
      "[144]\tvalid_0's multi_logloss: 0.159112\n",
      "[145]\tvalid_0's multi_logloss: 0.159128\n",
      "[146]\tvalid_0's multi_logloss: 0.15918\n",
      "[147]\tvalid_0's multi_logloss: 0.159229\n",
      "[148]\tvalid_0's multi_logloss: 0.159283\n",
      "[149]\tvalid_0's multi_logloss: 0.159317\n",
      "[150]\tvalid_0's multi_logloss: 0.159365\n",
      "[151]\tvalid_0's multi_logloss: 0.159432\n",
      "[152]\tvalid_0's multi_logloss: 0.159475\n",
      "[153]\tvalid_0's multi_logloss: 0.159501\n",
      "[154]\tvalid_0's multi_logloss: 0.159507\n",
      "[155]\tvalid_0's multi_logloss: 0.159522\n",
      "[156]\tvalid_0's multi_logloss: 0.159487\n",
      "[157]\tvalid_0's multi_logloss: 0.159495\n",
      "[158]\tvalid_0's multi_logloss: 0.159552\n",
      "[159]\tvalid_0's multi_logloss: 0.159533\n",
      "[160]\tvalid_0's multi_logloss: 0.159537\n",
      "[161]\tvalid_0's multi_logloss: 0.159542\n",
      "[162]\tvalid_0's multi_logloss: 0.159608\n",
      "[163]\tvalid_0's multi_logloss: 0.159604\n",
      "[164]\tvalid_0's multi_logloss: 0.159584\n",
      "[165]\tvalid_0's multi_logloss: 0.159585\n",
      "[166]\tvalid_0's multi_logloss: 0.159627\n",
      "[167]\tvalid_0's multi_logloss: 0.159634\n",
      "[168]\tvalid_0's multi_logloss: 0.159661\n",
      "[169]\tvalid_0's multi_logloss: 0.159641\n",
      "[170]\tvalid_0's multi_logloss: 0.1597\n",
      "[171]\tvalid_0's multi_logloss: 0.159735\n",
      "[172]\tvalid_0's multi_logloss: 0.159753\n",
      "[173]\tvalid_0's multi_logloss: 0.159789\n",
      "[174]\tvalid_0's multi_logloss: 0.159809\n",
      "[175]\tvalid_0's multi_logloss: 0.159823\n",
      "[176]\tvalid_0's multi_logloss: 0.159793\n",
      "[177]\tvalid_0's multi_logloss: 0.159818\n",
      "[178]\tvalid_0's multi_logloss: 0.159839\n",
      "[179]\tvalid_0's multi_logloss: 0.159861\n",
      "[180]\tvalid_0's multi_logloss: 0.159915\n",
      "[181]\tvalid_0's multi_logloss: 0.159932\n",
      "[182]\tvalid_0's multi_logloss: 0.159969\n",
      "[183]\tvalid_0's multi_logloss: 0.160024\n",
      "[184]\tvalid_0's multi_logloss: 0.160082\n",
      "[185]\tvalid_0's multi_logloss: 0.160129\n",
      "[186]\tvalid_0's multi_logloss: 0.160149\n",
      "[187]\tvalid_0's multi_logloss: 0.160145\n",
      "[188]\tvalid_0's multi_logloss: 0.160153\n",
      "[189]\tvalid_0's multi_logloss: 0.160129\n",
      "[190]\tvalid_0's multi_logloss: 0.160195\n",
      "[191]\tvalid_0's multi_logloss: 0.160208\n",
      "[192]\tvalid_0's multi_logloss: 0.160223\n",
      "[193]\tvalid_0's multi_logloss: 0.160252\n",
      "[194]\tvalid_0's multi_logloss: 0.160246\n",
      "[195]\tvalid_0's multi_logloss: 0.160334\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's multi_logloss: 0.158627\n",
      "training model for CV #7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.848775\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.743032\n",
      "[3]\tvalid_0's multi_logloss: 0.656354\n",
      "[4]\tvalid_0's multi_logloss: 0.587807\n",
      "[5]\tvalid_0's multi_logloss: 0.533424\n",
      "[6]\tvalid_0's multi_logloss: 0.485733\n",
      "[7]\tvalid_0's multi_logloss: 0.448721\n",
      "[8]\tvalid_0's multi_logloss: 0.412683\n",
      "[9]\tvalid_0's multi_logloss: 0.380154\n",
      "[10]\tvalid_0's multi_logloss: 0.354228\n",
      "[11]\tvalid_0's multi_logloss: 0.333303\n",
      "[12]\tvalid_0's multi_logloss: 0.315297\n",
      "[13]\tvalid_0's multi_logloss: 0.29838\n",
      "[14]\tvalid_0's multi_logloss: 0.283243\n",
      "[15]\tvalid_0's multi_logloss: 0.270898\n",
      "[16]\tvalid_0's multi_logloss: 0.259635\n",
      "[17]\tvalid_0's multi_logloss: 0.249105\n",
      "[18]\tvalid_0's multi_logloss: 0.238432\n",
      "[19]\tvalid_0's multi_logloss: 0.229487\n",
      "[20]\tvalid_0's multi_logloss: 0.22163\n",
      "[21]\tvalid_0's multi_logloss: 0.214543\n",
      "[22]\tvalid_0's multi_logloss: 0.20797\n",
      "[23]\tvalid_0's multi_logloss: 0.202508\n",
      "[24]\tvalid_0's multi_logloss: 0.198109\n",
      "[25]\tvalid_0's multi_logloss: 0.194264\n",
      "[26]\tvalid_0's multi_logloss: 0.190074\n",
      "[27]\tvalid_0's multi_logloss: 0.186482\n",
      "[28]\tvalid_0's multi_logloss: 0.183369\n",
      "[29]\tvalid_0's multi_logloss: 0.180671\n",
      "[30]\tvalid_0's multi_logloss: 0.178154\n",
      "[31]\tvalid_0's multi_logloss: 0.176198\n",
      "[32]\tvalid_0's multi_logloss: 0.174567\n",
      "[33]\tvalid_0's multi_logloss: 0.17335\n",
      "[34]\tvalid_0's multi_logloss: 0.171806\n",
      "[35]\tvalid_0's multi_logloss: 0.170514\n",
      "[36]\tvalid_0's multi_logloss: 0.169178\n",
      "[37]\tvalid_0's multi_logloss: 0.168357\n",
      "[38]\tvalid_0's multi_logloss: 0.167185\n",
      "[39]\tvalid_0's multi_logloss: 0.166143\n",
      "[40]\tvalid_0's multi_logloss: 0.165405\n",
      "[41]\tvalid_0's multi_logloss: 0.164385\n",
      "[42]\tvalid_0's multi_logloss: 0.163478\n",
      "[43]\tvalid_0's multi_logloss: 0.162923\n",
      "[44]\tvalid_0's multi_logloss: 0.162131\n",
      "[45]\tvalid_0's multi_logloss: 0.161537\n",
      "[46]\tvalid_0's multi_logloss: 0.160828\n",
      "[47]\tvalid_0's multi_logloss: 0.160359\n",
      "[48]\tvalid_0's multi_logloss: 0.159906\n",
      "[49]\tvalid_0's multi_logloss: 0.159541\n",
      "[50]\tvalid_0's multi_logloss: 0.15925\n",
      "[51]\tvalid_0's multi_logloss: 0.158904\n",
      "[52]\tvalid_0's multi_logloss: 0.158534\n",
      "[53]\tvalid_0's multi_logloss: 0.158071\n",
      "[54]\tvalid_0's multi_logloss: 0.157735\n",
      "[55]\tvalid_0's multi_logloss: 0.157487\n",
      "[56]\tvalid_0's multi_logloss: 0.157275\n",
      "[57]\tvalid_0's multi_logloss: 0.157055\n",
      "[58]\tvalid_0's multi_logloss: 0.156855\n",
      "[59]\tvalid_0's multi_logloss: 0.156688\n",
      "[60]\tvalid_0's multi_logloss: 0.156477\n",
      "[61]\tvalid_0's multi_logloss: 0.156239\n",
      "[62]\tvalid_0's multi_logloss: 0.156069\n",
      "[63]\tvalid_0's multi_logloss: 0.155951\n",
      "[64]\tvalid_0's multi_logloss: 0.155684\n",
      "[65]\tvalid_0's multi_logloss: 0.155509\n",
      "[66]\tvalid_0's multi_logloss: 0.15543\n",
      "[67]\tvalid_0's multi_logloss: 0.155364\n",
      "[68]\tvalid_0's multi_logloss: 0.155264\n",
      "[69]\tvalid_0's multi_logloss: 0.155091\n",
      "[70]\tvalid_0's multi_logloss: 0.155032\n",
      "[71]\tvalid_0's multi_logloss: 0.154854\n",
      "[72]\tvalid_0's multi_logloss: 0.154773\n",
      "[73]\tvalid_0's multi_logloss: 0.154748\n",
      "[74]\tvalid_0's multi_logloss: 0.154628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75]\tvalid_0's multi_logloss: 0.154537\n",
      "[76]\tvalid_0's multi_logloss: 0.154372\n",
      "[77]\tvalid_0's multi_logloss: 0.154303\n",
      "[78]\tvalid_0's multi_logloss: 0.154233\n",
      "[79]\tvalid_0's multi_logloss: 0.15419\n",
      "[80]\tvalid_0's multi_logloss: 0.154116\n",
      "[81]\tvalid_0's multi_logloss: 0.154108\n",
      "[82]\tvalid_0's multi_logloss: 0.154051\n",
      "[83]\tvalid_0's multi_logloss: 0.15397\n",
      "[84]\tvalid_0's multi_logloss: 0.153912\n",
      "[85]\tvalid_0's multi_logloss: 0.153815\n",
      "[86]\tvalid_0's multi_logloss: 0.153788\n",
      "[87]\tvalid_0's multi_logloss: 0.153752\n",
      "[88]\tvalid_0's multi_logloss: 0.15369\n",
      "[89]\tvalid_0's multi_logloss: 0.153662\n",
      "[90]\tvalid_0's multi_logloss: 0.153658\n",
      "[91]\tvalid_0's multi_logloss: 0.153642\n",
      "[92]\tvalid_0's multi_logloss: 0.153622\n",
      "[93]\tvalid_0's multi_logloss: 0.153636\n",
      "[94]\tvalid_0's multi_logloss: 0.153568\n",
      "[95]\tvalid_0's multi_logloss: 0.153556\n",
      "[96]\tvalid_0's multi_logloss: 0.15355\n",
      "[97]\tvalid_0's multi_logloss: 0.153562\n",
      "[98]\tvalid_0's multi_logloss: 0.15351\n",
      "[99]\tvalid_0's multi_logloss: 0.153485\n",
      "[100]\tvalid_0's multi_logloss: 0.153466\n",
      "[101]\tvalid_0's multi_logloss: 0.153493\n",
      "[102]\tvalid_0's multi_logloss: 0.153477\n",
      "[103]\tvalid_0's multi_logloss: 0.153466\n",
      "[104]\tvalid_0's multi_logloss: 0.153451\n",
      "[105]\tvalid_0's multi_logloss: 0.153455\n",
      "[106]\tvalid_0's multi_logloss: 0.15346\n",
      "[107]\tvalid_0's multi_logloss: 0.153446\n",
      "[108]\tvalid_0's multi_logloss: 0.153436\n",
      "[109]\tvalid_0's multi_logloss: 0.153435\n",
      "[110]\tvalid_0's multi_logloss: 0.153434\n",
      "[111]\tvalid_0's multi_logloss: 0.15344\n",
      "[112]\tvalid_0's multi_logloss: 0.153486\n",
      "[113]\tvalid_0's multi_logloss: 0.153487\n",
      "[114]\tvalid_0's multi_logloss: 0.153451\n",
      "[115]\tvalid_0's multi_logloss: 0.153458\n",
      "[116]\tvalid_0's multi_logloss: 0.153439\n",
      "[117]\tvalid_0's multi_logloss: 0.153423\n",
      "[118]\tvalid_0's multi_logloss: 0.153413\n",
      "[119]\tvalid_0's multi_logloss: 0.153448\n",
      "[120]\tvalid_0's multi_logloss: 0.153454\n",
      "[121]\tvalid_0's multi_logloss: 0.153394\n",
      "[122]\tvalid_0's multi_logloss: 0.153421\n",
      "[123]\tvalid_0's multi_logloss: 0.153478\n",
      "[124]\tvalid_0's multi_logloss: 0.153471\n",
      "[125]\tvalid_0's multi_logloss: 0.153481\n",
      "[126]\tvalid_0's multi_logloss: 0.153487\n",
      "[127]\tvalid_0's multi_logloss: 0.153483\n",
      "[128]\tvalid_0's multi_logloss: 0.153498\n",
      "[129]\tvalid_0's multi_logloss: 0.153521\n",
      "[130]\tvalid_0's multi_logloss: 0.153527\n",
      "[131]\tvalid_0's multi_logloss: 0.153595\n",
      "[132]\tvalid_0's multi_logloss: 0.153603\n",
      "[133]\tvalid_0's multi_logloss: 0.153598\n",
      "[134]\tvalid_0's multi_logloss: 0.153578\n",
      "[135]\tvalid_0's multi_logloss: 0.153625\n",
      "[136]\tvalid_0's multi_logloss: 0.153613\n",
      "[137]\tvalid_0's multi_logloss: 0.153662\n",
      "[138]\tvalid_0's multi_logloss: 0.153663\n",
      "[139]\tvalid_0's multi_logloss: 0.153681\n",
      "[140]\tvalid_0's multi_logloss: 0.153731\n",
      "[141]\tvalid_0's multi_logloss: 0.153742\n",
      "[142]\tvalid_0's multi_logloss: 0.153763\n",
      "[143]\tvalid_0's multi_logloss: 0.153784\n",
      "[144]\tvalid_0's multi_logloss: 0.153829\n",
      "[145]\tvalid_0's multi_logloss: 0.153868\n",
      "[146]\tvalid_0's multi_logloss: 0.153934\n",
      "[147]\tvalid_0's multi_logloss: 0.15395\n",
      "[148]\tvalid_0's multi_logloss: 0.153908\n",
      "[149]\tvalid_0's multi_logloss: 0.153891\n",
      "[150]\tvalid_0's multi_logloss: 0.153907\n",
      "[151]\tvalid_0's multi_logloss: 0.153894\n",
      "[152]\tvalid_0's multi_logloss: 0.153946\n",
      "[153]\tvalid_0's multi_logloss: 0.153985\n",
      "[154]\tvalid_0's multi_logloss: 0.154044\n",
      "[155]\tvalid_0's multi_logloss: 0.154037\n",
      "[156]\tvalid_0's multi_logloss: 0.154056\n",
      "[157]\tvalid_0's multi_logloss: 0.154094\n",
      "[158]\tvalid_0's multi_logloss: 0.154068\n",
      "[159]\tvalid_0's multi_logloss: 0.154092\n",
      "[160]\tvalid_0's multi_logloss: 0.154138\n",
      "[161]\tvalid_0's multi_logloss: 0.154153\n",
      "[162]\tvalid_0's multi_logloss: 0.154226\n",
      "[163]\tvalid_0's multi_logloss: 0.154231\n",
      "[164]\tvalid_0's multi_logloss: 0.154261\n",
      "[165]\tvalid_0's multi_logloss: 0.154226\n",
      "[166]\tvalid_0's multi_logloss: 0.154248\n",
      "[167]\tvalid_0's multi_logloss: 0.154285\n",
      "[168]\tvalid_0's multi_logloss: 0.154295\n",
      "[169]\tvalid_0's multi_logloss: 0.154307\n",
      "[170]\tvalid_0's multi_logloss: 0.154363\n",
      "[171]\tvalid_0's multi_logloss: 0.154343\n",
      "[172]\tvalid_0's multi_logloss: 0.154365\n",
      "[173]\tvalid_0's multi_logloss: 0.154419\n",
      "[174]\tvalid_0's multi_logloss: 0.154432\n",
      "[175]\tvalid_0's multi_logloss: 0.154457\n",
      "[176]\tvalid_0's multi_logloss: 0.154496\n",
      "[177]\tvalid_0's multi_logloss: 0.154487\n",
      "[178]\tvalid_0's multi_logloss: 0.154497\n",
      "[179]\tvalid_0's multi_logloss: 0.154521\n",
      "[180]\tvalid_0's multi_logloss: 0.154549\n",
      "[181]\tvalid_0's multi_logloss: 0.154494\n",
      "[182]\tvalid_0's multi_logloss: 0.154436\n",
      "[183]\tvalid_0's multi_logloss: 0.154434\n",
      "[184]\tvalid_0's multi_logloss: 0.154447\n",
      "[185]\tvalid_0's multi_logloss: 0.154453\n",
      "[186]\tvalid_0's multi_logloss: 0.154487\n",
      "[187]\tvalid_0's multi_logloss: 0.154517\n",
      "[188]\tvalid_0's multi_logloss: 0.154574\n",
      "[189]\tvalid_0's multi_logloss: 0.154626\n",
      "[190]\tvalid_0's multi_logloss: 0.154633\n",
      "[191]\tvalid_0's multi_logloss: 0.154642\n",
      "[192]\tvalid_0's multi_logloss: 0.154679\n",
      "[193]\tvalid_0's multi_logloss: 0.154721\n",
      "[194]\tvalid_0's multi_logloss: 0.15475\n",
      "[195]\tvalid_0's multi_logloss: 0.154775\n",
      "[196]\tvalid_0's multi_logloss: 0.154801\n",
      "[197]\tvalid_0's multi_logloss: 0.154775\n",
      "[198]\tvalid_0's multi_logloss: 0.15482\n",
      "[199]\tvalid_0's multi_logloss: 0.154789\n",
      "[200]\tvalid_0's multi_logloss: 0.154805\n",
      "[201]\tvalid_0's multi_logloss: 0.154799\n",
      "[202]\tvalid_0's multi_logloss: 0.15483\n",
      "[203]\tvalid_0's multi_logloss: 0.154891\n",
      "[204]\tvalid_0's multi_logloss: 0.154896\n",
      "[205]\tvalid_0's multi_logloss: 0.15494\n",
      "[206]\tvalid_0's multi_logloss: 0.154922\n",
      "[207]\tvalid_0's multi_logloss: 0.154977\n",
      "[208]\tvalid_0's multi_logloss: 0.154957\n",
      "[209]\tvalid_0's multi_logloss: 0.154978\n",
      "[210]\tvalid_0's multi_logloss: 0.155029\n",
      "[211]\tvalid_0's multi_logloss: 0.155037\n",
      "[212]\tvalid_0's multi_logloss: 0.155046\n",
      "[213]\tvalid_0's multi_logloss: 0.155024\n",
      "[214]\tvalid_0's multi_logloss: 0.154994\n",
      "[215]\tvalid_0's multi_logloss: 0.154986\n",
      "[216]\tvalid_0's multi_logloss: 0.154994\n",
      "[217]\tvalid_0's multi_logloss: 0.154983\n",
      "[218]\tvalid_0's multi_logloss: 0.154976\n",
      "[219]\tvalid_0's multi_logloss: 0.155024\n",
      "[220]\tvalid_0's multi_logloss: 0.155082\n",
      "[221]\tvalid_0's multi_logloss: 0.155117\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.153394\n",
      "training model for CV #8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.849728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.744892\n",
      "[3]\tvalid_0's multi_logloss: 0.658655\n",
      "[4]\tvalid_0's multi_logloss: 0.590448\n",
      "[5]\tvalid_0's multi_logloss: 0.536558\n",
      "[6]\tvalid_0's multi_logloss: 0.489186\n",
      "[7]\tvalid_0's multi_logloss: 0.452447\n",
      "[8]\tvalid_0's multi_logloss: 0.416352\n",
      "[9]\tvalid_0's multi_logloss: 0.38389\n",
      "[10]\tvalid_0's multi_logloss: 0.358115\n",
      "[11]\tvalid_0's multi_logloss: 0.337314\n",
      "[12]\tvalid_0's multi_logloss: 0.319431\n",
      "[13]\tvalid_0's multi_logloss: 0.302554\n",
      "[14]\tvalid_0's multi_logloss: 0.28748\n",
      "[15]\tvalid_0's multi_logloss: 0.275211\n",
      "[16]\tvalid_0's multi_logloss: 0.264029\n",
      "[17]\tvalid_0's multi_logloss: 0.253637\n",
      "[18]\tvalid_0's multi_logloss: 0.242987\n",
      "[19]\tvalid_0's multi_logloss: 0.234094\n",
      "[20]\tvalid_0's multi_logloss: 0.226313\n",
      "[21]\tvalid_0's multi_logloss: 0.219115\n",
      "[22]\tvalid_0's multi_logloss: 0.212655\n",
      "[23]\tvalid_0's multi_logloss: 0.20702\n",
      "[24]\tvalid_0's multi_logloss: 0.202686\n",
      "[25]\tvalid_0's multi_logloss: 0.19885\n",
      "[26]\tvalid_0's multi_logloss: 0.194514\n",
      "[27]\tvalid_0's multi_logloss: 0.190925\n",
      "[28]\tvalid_0's multi_logloss: 0.187836\n",
      "[29]\tvalid_0's multi_logloss: 0.18509\n",
      "[30]\tvalid_0's multi_logloss: 0.182497\n",
      "[31]\tvalid_0's multi_logloss: 0.180442\n",
      "[32]\tvalid_0's multi_logloss: 0.178667\n",
      "[33]\tvalid_0's multi_logloss: 0.177512\n",
      "[34]\tvalid_0's multi_logloss: 0.175901\n",
      "[35]\tvalid_0's multi_logloss: 0.174606\n",
      "[36]\tvalid_0's multi_logloss: 0.173225\n",
      "[37]\tvalid_0's multi_logloss: 0.172401\n",
      "[38]\tvalid_0's multi_logloss: 0.171264\n",
      "[39]\tvalid_0's multi_logloss: 0.170186\n",
      "[40]\tvalid_0's multi_logloss: 0.16931\n",
      "[41]\tvalid_0's multi_logloss: 0.168248\n",
      "[42]\tvalid_0's multi_logloss: 0.167316\n",
      "[43]\tvalid_0's multi_logloss: 0.166734\n",
      "[44]\tvalid_0's multi_logloss: 0.165966\n",
      "[45]\tvalid_0's multi_logloss: 0.165372\n",
      "[46]\tvalid_0's multi_logloss: 0.164695\n",
      "[47]\tvalid_0's multi_logloss: 0.164265\n",
      "[48]\tvalid_0's multi_logloss: 0.1639\n",
      "[49]\tvalid_0's multi_logloss: 0.163516\n",
      "[50]\tvalid_0's multi_logloss: 0.163177\n",
      "[51]\tvalid_0's multi_logloss: 0.162786\n",
      "[52]\tvalid_0's multi_logloss: 0.162454\n",
      "[53]\tvalid_0's multi_logloss: 0.161995\n",
      "[54]\tvalid_0's multi_logloss: 0.16165\n",
      "[55]\tvalid_0's multi_logloss: 0.161341\n",
      "[56]\tvalid_0's multi_logloss: 0.161219\n",
      "[57]\tvalid_0's multi_logloss: 0.161031\n",
      "[58]\tvalid_0's multi_logloss: 0.160822\n",
      "[59]\tvalid_0's multi_logloss: 0.16066\n",
      "[60]\tvalid_0's multi_logloss: 0.16051\n",
      "[61]\tvalid_0's multi_logloss: 0.160203\n",
      "[62]\tvalid_0's multi_logloss: 0.160028\n",
      "[63]\tvalid_0's multi_logloss: 0.159928\n",
      "[64]\tvalid_0's multi_logloss: 0.159714\n",
      "[65]\tvalid_0's multi_logloss: 0.159597\n",
      "[66]\tvalid_0's multi_logloss: 0.159543\n",
      "[67]\tvalid_0's multi_logloss: 0.159512\n",
      "[68]\tvalid_0's multi_logloss: 0.159409\n",
      "[69]\tvalid_0's multi_logloss: 0.159255\n",
      "[70]\tvalid_0's multi_logloss: 0.159211\n",
      "[71]\tvalid_0's multi_logloss: 0.159046\n",
      "[72]\tvalid_0's multi_logloss: 0.158941\n",
      "[73]\tvalid_0's multi_logloss: 0.158872\n",
      "[74]\tvalid_0's multi_logloss: 0.158741\n",
      "[75]\tvalid_0's multi_logloss: 0.158651\n",
      "[76]\tvalid_0's multi_logloss: 0.158439\n",
      "[77]\tvalid_0's multi_logloss: 0.158318\n",
      "[78]\tvalid_0's multi_logloss: 0.158264\n",
      "[79]\tvalid_0's multi_logloss: 0.158209\n",
      "[80]\tvalid_0's multi_logloss: 0.158108\n",
      "[81]\tvalid_0's multi_logloss: 0.158071\n",
      "[82]\tvalid_0's multi_logloss: 0.158052\n",
      "[83]\tvalid_0's multi_logloss: 0.157954\n",
      "[84]\tvalid_0's multi_logloss: 0.157933\n",
      "[85]\tvalid_0's multi_logloss: 0.15789\n",
      "[86]\tvalid_0's multi_logloss: 0.157841\n",
      "[87]\tvalid_0's multi_logloss: 0.157791\n",
      "[88]\tvalid_0's multi_logloss: 0.15772\n",
      "[89]\tvalid_0's multi_logloss: 0.157724\n",
      "[90]\tvalid_0's multi_logloss: 0.157648\n",
      "[91]\tvalid_0's multi_logloss: 0.157619\n",
      "[92]\tvalid_0's multi_logloss: 0.157547\n",
      "[93]\tvalid_0's multi_logloss: 0.157536\n",
      "[94]\tvalid_0's multi_logloss: 0.157549\n",
      "[95]\tvalid_0's multi_logloss: 0.15751\n",
      "[96]\tvalid_0's multi_logloss: 0.157517\n",
      "[97]\tvalid_0's multi_logloss: 0.157505\n",
      "[98]\tvalid_0's multi_logloss: 0.157542\n",
      "[99]\tvalid_0's multi_logloss: 0.15753\n",
      "[100]\tvalid_0's multi_logloss: 0.157567\n",
      "[101]\tvalid_0's multi_logloss: 0.157568\n",
      "[102]\tvalid_0's multi_logloss: 0.157559\n",
      "[103]\tvalid_0's multi_logloss: 0.15754\n",
      "[104]\tvalid_0's multi_logloss: 0.15749\n",
      "[105]\tvalid_0's multi_logloss: 0.157478\n",
      "[106]\tvalid_0's multi_logloss: 0.157483\n",
      "[107]\tvalid_0's multi_logloss: 0.157428\n",
      "[108]\tvalid_0's multi_logloss: 0.157393\n",
      "[109]\tvalid_0's multi_logloss: 0.157381\n",
      "[110]\tvalid_0's multi_logloss: 0.157365\n",
      "[111]\tvalid_0's multi_logloss: 0.157382\n",
      "[112]\tvalid_0's multi_logloss: 0.157417\n",
      "[113]\tvalid_0's multi_logloss: 0.157408\n",
      "[114]\tvalid_0's multi_logloss: 0.157409\n",
      "[115]\tvalid_0's multi_logloss: 0.157411\n",
      "[116]\tvalid_0's multi_logloss: 0.157461\n",
      "[117]\tvalid_0's multi_logloss: 0.157464\n",
      "[118]\tvalid_0's multi_logloss: 0.157514\n",
      "[119]\tvalid_0's multi_logloss: 0.157522\n",
      "[120]\tvalid_0's multi_logloss: 0.157489\n",
      "[121]\tvalid_0's multi_logloss: 0.15751\n",
      "[122]\tvalid_0's multi_logloss: 0.15754\n",
      "[123]\tvalid_0's multi_logloss: 0.157552\n",
      "[124]\tvalid_0's multi_logloss: 0.157605\n",
      "[125]\tvalid_0's multi_logloss: 0.157606\n",
      "[126]\tvalid_0's multi_logloss: 0.157577\n",
      "[127]\tvalid_0's multi_logloss: 0.157572\n",
      "[128]\tvalid_0's multi_logloss: 0.15759\n",
      "[129]\tvalid_0's multi_logloss: 0.157597\n",
      "[130]\tvalid_0's multi_logloss: 0.157611\n",
      "[131]\tvalid_0's multi_logloss: 0.157638\n",
      "[132]\tvalid_0's multi_logloss: 0.157668\n",
      "[133]\tvalid_0's multi_logloss: 0.157649\n",
      "[134]\tvalid_0's multi_logloss: 0.157691\n",
      "[135]\tvalid_0's multi_logloss: 0.157701\n",
      "[136]\tvalid_0's multi_logloss: 0.157714\n",
      "[137]\tvalid_0's multi_logloss: 0.157717\n",
      "[138]\tvalid_0's multi_logloss: 0.15775\n",
      "[139]\tvalid_0's multi_logloss: 0.157771\n",
      "[140]\tvalid_0's multi_logloss: 0.157814\n",
      "[141]\tvalid_0's multi_logloss: 0.157785\n",
      "[142]\tvalid_0's multi_logloss: 0.15777\n",
      "[143]\tvalid_0's multi_logloss: 0.157773\n",
      "[144]\tvalid_0's multi_logloss: 0.157765\n",
      "[145]\tvalid_0's multi_logloss: 0.15775\n",
      "[146]\tvalid_0's multi_logloss: 0.157709\n",
      "[147]\tvalid_0's multi_logloss: 0.157707\n",
      "[148]\tvalid_0's multi_logloss: 0.157729\n",
      "[149]\tvalid_0's multi_logloss: 0.157748\n",
      "[150]\tvalid_0's multi_logloss: 0.157739\n",
      "[151]\tvalid_0's multi_logloss: 0.157753\n",
      "[152]\tvalid_0's multi_logloss: 0.157795\n",
      "[153]\tvalid_0's multi_logloss: 0.157798\n",
      "[154]\tvalid_0's multi_logloss: 0.157847\n",
      "[155]\tvalid_0's multi_logloss: 0.157852\n",
      "[156]\tvalid_0's multi_logloss: 0.157875\n",
      "[157]\tvalid_0's multi_logloss: 0.157884\n",
      "[158]\tvalid_0's multi_logloss: 0.157894\n",
      "[159]\tvalid_0's multi_logloss: 0.157894\n",
      "[160]\tvalid_0's multi_logloss: 0.157877\n",
      "[161]\tvalid_0's multi_logloss: 0.15793\n",
      "[162]\tvalid_0's multi_logloss: 0.157997\n",
      "[163]\tvalid_0's multi_logloss: 0.157955\n",
      "[164]\tvalid_0's multi_logloss: 0.157979\n",
      "[165]\tvalid_0's multi_logloss: 0.157992\n",
      "[166]\tvalid_0's multi_logloss: 0.158064\n",
      "[167]\tvalid_0's multi_logloss: 0.158057\n",
      "[168]\tvalid_0's multi_logloss: 0.158084\n",
      "[169]\tvalid_0's multi_logloss: 0.158076\n",
      "[170]\tvalid_0's multi_logloss: 0.158034\n",
      "[171]\tvalid_0's multi_logloss: 0.15806\n",
      "[172]\tvalid_0's multi_logloss: 0.158087\n",
      "[173]\tvalid_0's multi_logloss: 0.158105\n",
      "[174]\tvalid_0's multi_logloss: 0.158138\n",
      "[175]\tvalid_0's multi_logloss: 0.158201\n",
      "[176]\tvalid_0's multi_logloss: 0.158215\n",
      "[177]\tvalid_0's multi_logloss: 0.158212\n",
      "[178]\tvalid_0's multi_logloss: 0.15826\n",
      "[179]\tvalid_0's multi_logloss: 0.158276\n",
      "[180]\tvalid_0's multi_logloss: 0.158294\n",
      "[181]\tvalid_0's multi_logloss: 0.158316\n",
      "[182]\tvalid_0's multi_logloss: 0.158376\n",
      "[183]\tvalid_0's multi_logloss: 0.158362\n",
      "[184]\tvalid_0's multi_logloss: 0.158428\n",
      "[185]\tvalid_0's multi_logloss: 0.158497\n",
      "[186]\tvalid_0's multi_logloss: 0.158531\n",
      "[187]\tvalid_0's multi_logloss: 0.158548\n",
      "[188]\tvalid_0's multi_logloss: 0.158589\n",
      "[189]\tvalid_0's multi_logloss: 0.158616\n",
      "[190]\tvalid_0's multi_logloss: 0.158639\n",
      "[191]\tvalid_0's multi_logloss: 0.158669\n",
      "[192]\tvalid_0's multi_logloss: 0.158695\n",
      "[193]\tvalid_0's multi_logloss: 0.158684\n",
      "[194]\tvalid_0's multi_logloss: 0.158738\n",
      "[195]\tvalid_0's multi_logloss: 0.158753\n",
      "[196]\tvalid_0's multi_logloss: 0.158751\n",
      "[197]\tvalid_0's multi_logloss: 0.158773\n",
      "[198]\tvalid_0's multi_logloss: 0.158807\n",
      "[199]\tvalid_0's multi_logloss: 0.158796\n",
      "[200]\tvalid_0's multi_logloss: 0.158797\n",
      "[201]\tvalid_0's multi_logloss: 0.158838\n",
      "[202]\tvalid_0's multi_logloss: 0.158905\n",
      "[203]\tvalid_0's multi_logloss: 0.158965\n",
      "[204]\tvalid_0's multi_logloss: 0.159008\n",
      "[205]\tvalid_0's multi_logloss: 0.159038\n",
      "[206]\tvalid_0's multi_logloss: 0.159059\n",
      "[207]\tvalid_0's multi_logloss: 0.15907\n",
      "[208]\tvalid_0's multi_logloss: 0.159075\n",
      "[209]\tvalid_0's multi_logloss: 0.159107\n",
      "[210]\tvalid_0's multi_logloss: 0.159132\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.157365\n",
      "training model for CV #9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.848234\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.743058\n",
      "[3]\tvalid_0's multi_logloss: 0.656316\n",
      "[4]\tvalid_0's multi_logloss: 0.587568\n",
      "[5]\tvalid_0's multi_logloss: 0.533349\n",
      "[6]\tvalid_0's multi_logloss: 0.485681\n",
      "[7]\tvalid_0's multi_logloss: 0.448771\n",
      "[8]\tvalid_0's multi_logloss: 0.412612\n",
      "[9]\tvalid_0's multi_logloss: 0.379996\n",
      "[10]\tvalid_0's multi_logloss: 0.354052\n",
      "[11]\tvalid_0's multi_logloss: 0.332949\n",
      "[12]\tvalid_0's multi_logloss: 0.314888\n",
      "[13]\tvalid_0's multi_logloss: 0.297775\n",
      "[14]\tvalid_0's multi_logloss: 0.282599\n",
      "[15]\tvalid_0's multi_logloss: 0.270076\n",
      "[16]\tvalid_0's multi_logloss: 0.258735\n",
      "[17]\tvalid_0's multi_logloss: 0.248288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\tvalid_0's multi_logloss: 0.237574\n",
      "[19]\tvalid_0's multi_logloss: 0.228644\n",
      "[20]\tvalid_0's multi_logloss: 0.22071\n",
      "[21]\tvalid_0's multi_logloss: 0.213475\n",
      "[22]\tvalid_0's multi_logloss: 0.206837\n",
      "[23]\tvalid_0's multi_logloss: 0.201162\n",
      "[24]\tvalid_0's multi_logloss: 0.196864\n",
      "[25]\tvalid_0's multi_logloss: 0.192919\n",
      "[26]\tvalid_0's multi_logloss: 0.188677\n",
      "[27]\tvalid_0's multi_logloss: 0.185075\n",
      "[28]\tvalid_0's multi_logloss: 0.181895\n",
      "[29]\tvalid_0's multi_logloss: 0.17915\n",
      "[30]\tvalid_0's multi_logloss: 0.176536\n",
      "[31]\tvalid_0's multi_logloss: 0.174521\n",
      "[32]\tvalid_0's multi_logloss: 0.172812\n",
      "[33]\tvalid_0's multi_logloss: 0.171642\n",
      "[34]\tvalid_0's multi_logloss: 0.170112\n",
      "[35]\tvalid_0's multi_logloss: 0.168802\n",
      "[36]\tvalid_0's multi_logloss: 0.167441\n",
      "[37]\tvalid_0's multi_logloss: 0.166627\n",
      "[38]\tvalid_0's multi_logloss: 0.165493\n",
      "[39]\tvalid_0's multi_logloss: 0.164458\n",
      "[40]\tvalid_0's multi_logloss: 0.163662\n",
      "[41]\tvalid_0's multi_logloss: 0.162711\n",
      "[42]\tvalid_0's multi_logloss: 0.161676\n",
      "[43]\tvalid_0's multi_logloss: 0.161168\n",
      "[44]\tvalid_0's multi_logloss: 0.160358\n",
      "[45]\tvalid_0's multi_logloss: 0.159735\n",
      "[46]\tvalid_0's multi_logloss: 0.15895\n",
      "[47]\tvalid_0's multi_logloss: 0.158464\n",
      "[48]\tvalid_0's multi_logloss: 0.15806\n",
      "[49]\tvalid_0's multi_logloss: 0.157697\n",
      "[50]\tvalid_0's multi_logloss: 0.1574\n",
      "[51]\tvalid_0's multi_logloss: 0.15706\n",
      "[52]\tvalid_0's multi_logloss: 0.156683\n",
      "[53]\tvalid_0's multi_logloss: 0.156212\n",
      "[54]\tvalid_0's multi_logloss: 0.155944\n",
      "[55]\tvalid_0's multi_logloss: 0.155767\n",
      "[56]\tvalid_0's multi_logloss: 0.155509\n",
      "[57]\tvalid_0's multi_logloss: 0.155178\n",
      "[58]\tvalid_0's multi_logloss: 0.154957\n",
      "[59]\tvalid_0's multi_logloss: 0.154808\n",
      "[60]\tvalid_0's multi_logloss: 0.154659\n",
      "[61]\tvalid_0's multi_logloss: 0.154475\n",
      "[62]\tvalid_0's multi_logloss: 0.154305\n",
      "[63]\tvalid_0's multi_logloss: 0.154238\n",
      "[64]\tvalid_0's multi_logloss: 0.154024\n",
      "[65]\tvalid_0's multi_logloss: 0.153845\n",
      "[66]\tvalid_0's multi_logloss: 0.15381\n",
      "[67]\tvalid_0's multi_logloss: 0.1537\n",
      "[68]\tvalid_0's multi_logloss: 0.153583\n",
      "[69]\tvalid_0's multi_logloss: 0.153458\n",
      "[70]\tvalid_0's multi_logloss: 0.153423\n",
      "[71]\tvalid_0's multi_logloss: 0.153297\n",
      "[72]\tvalid_0's multi_logloss: 0.153241\n",
      "[73]\tvalid_0's multi_logloss: 0.153101\n",
      "[74]\tvalid_0's multi_logloss: 0.153091\n",
      "[75]\tvalid_0's multi_logloss: 0.152968\n",
      "[76]\tvalid_0's multi_logloss: 0.152817\n",
      "[77]\tvalid_0's multi_logloss: 0.152768\n",
      "[78]\tvalid_0's multi_logloss: 0.152693\n",
      "[79]\tvalid_0's multi_logloss: 0.152684\n",
      "[80]\tvalid_0's multi_logloss: 0.152636\n",
      "[81]\tvalid_0's multi_logloss: 0.152554\n",
      "[82]\tvalid_0's multi_logloss: 0.152491\n",
      "[83]\tvalid_0's multi_logloss: 0.152392\n",
      "[84]\tvalid_0's multi_logloss: 0.152291\n",
      "[85]\tvalid_0's multi_logloss: 0.152244\n",
      "[86]\tvalid_0's multi_logloss: 0.152228\n",
      "[87]\tvalid_0's multi_logloss: 0.152168\n",
      "[88]\tvalid_0's multi_logloss: 0.152054\n",
      "[89]\tvalid_0's multi_logloss: 0.152029\n",
      "[90]\tvalid_0's multi_logloss: 0.152007\n",
      "[91]\tvalid_0's multi_logloss: 0.152005\n",
      "[92]\tvalid_0's multi_logloss: 0.151975\n",
      "[93]\tvalid_0's multi_logloss: 0.151971\n",
      "[94]\tvalid_0's multi_logloss: 0.151936\n",
      "[95]\tvalid_0's multi_logloss: 0.151926\n",
      "[96]\tvalid_0's multi_logloss: 0.15188\n",
      "[97]\tvalid_0's multi_logloss: 0.151894\n",
      "[98]\tvalid_0's multi_logloss: 0.15189\n",
      "[99]\tvalid_0's multi_logloss: 0.151861\n",
      "[100]\tvalid_0's multi_logloss: 0.151812\n",
      "[101]\tvalid_0's multi_logloss: 0.151768\n",
      "[102]\tvalid_0's multi_logloss: 0.151744\n",
      "[103]\tvalid_0's multi_logloss: 0.151693\n",
      "[104]\tvalid_0's multi_logloss: 0.151671\n",
      "[105]\tvalid_0's multi_logloss: 0.151769\n",
      "[106]\tvalid_0's multi_logloss: 0.151747\n",
      "[107]\tvalid_0's multi_logloss: 0.151703\n",
      "[108]\tvalid_0's multi_logloss: 0.151672\n",
      "[109]\tvalid_0's multi_logloss: 0.151695\n",
      "[110]\tvalid_0's multi_logloss: 0.151671\n",
      "[111]\tvalid_0's multi_logloss: 0.151647\n",
      "[112]\tvalid_0's multi_logloss: 0.151687\n",
      "[113]\tvalid_0's multi_logloss: 0.151725\n",
      "[114]\tvalid_0's multi_logloss: 0.151719\n",
      "[115]\tvalid_0's multi_logloss: 0.151743\n",
      "[116]\tvalid_0's multi_logloss: 0.151782\n",
      "[117]\tvalid_0's multi_logloss: 0.151796\n",
      "[118]\tvalid_0's multi_logloss: 0.151732\n",
      "[119]\tvalid_0's multi_logloss: 0.151767\n",
      "[120]\tvalid_0's multi_logloss: 0.151799\n",
      "[121]\tvalid_0's multi_logloss: 0.151796\n",
      "[122]\tvalid_0's multi_logloss: 0.151771\n",
      "[123]\tvalid_0's multi_logloss: 0.151775\n",
      "[124]\tvalid_0's multi_logloss: 0.151752\n",
      "[125]\tvalid_0's multi_logloss: 0.151763\n",
      "[126]\tvalid_0's multi_logloss: 0.151794\n",
      "[127]\tvalid_0's multi_logloss: 0.151839\n",
      "[128]\tvalid_0's multi_logloss: 0.151836\n",
      "[129]\tvalid_0's multi_logloss: 0.151889\n",
      "[130]\tvalid_0's multi_logloss: 0.151821\n",
      "[131]\tvalid_0's multi_logloss: 0.151842\n",
      "[132]\tvalid_0's multi_logloss: 0.151843\n",
      "[133]\tvalid_0's multi_logloss: 0.151852\n",
      "[134]\tvalid_0's multi_logloss: 0.151837\n",
      "[135]\tvalid_0's multi_logloss: 0.151846\n",
      "[136]\tvalid_0's multi_logloss: 0.151851\n",
      "[137]\tvalid_0's multi_logloss: 0.151852\n",
      "[138]\tvalid_0's multi_logloss: 0.151832\n",
      "[139]\tvalid_0's multi_logloss: 0.151805\n",
      "[140]\tvalid_0's multi_logloss: 0.151815\n",
      "[141]\tvalid_0's multi_logloss: 0.151837\n",
      "[142]\tvalid_0's multi_logloss: 0.151834\n",
      "[143]\tvalid_0's multi_logloss: 0.151848\n",
      "[144]\tvalid_0's multi_logloss: 0.15188\n",
      "[145]\tvalid_0's multi_logloss: 0.151878\n",
      "[146]\tvalid_0's multi_logloss: 0.151877\n",
      "[147]\tvalid_0's multi_logloss: 0.151896\n",
      "[148]\tvalid_0's multi_logloss: 0.151925\n",
      "[149]\tvalid_0's multi_logloss: 0.151945\n",
      "[150]\tvalid_0's multi_logloss: 0.151948\n",
      "[151]\tvalid_0's multi_logloss: 0.151931\n",
      "[152]\tvalid_0's multi_logloss: 0.151954\n",
      "[153]\tvalid_0's multi_logloss: 0.151979\n",
      "[154]\tvalid_0's multi_logloss: 0.152014\n",
      "[155]\tvalid_0's multi_logloss: 0.152032\n",
      "[156]\tvalid_0's multi_logloss: 0.152021\n",
      "[157]\tvalid_0's multi_logloss: 0.152063\n",
      "[158]\tvalid_0's multi_logloss: 0.152068\n",
      "[159]\tvalid_0's multi_logloss: 0.152114\n",
      "[160]\tvalid_0's multi_logloss: 0.152138\n",
      "[161]\tvalid_0's multi_logloss: 0.152141\n",
      "[162]\tvalid_0's multi_logloss: 0.152198\n",
      "[163]\tvalid_0's multi_logloss: 0.152185\n",
      "[164]\tvalid_0's multi_logloss: 0.15219\n",
      "[165]\tvalid_0's multi_logloss: 0.152235\n",
      "[166]\tvalid_0's multi_logloss: 0.152275\n",
      "[167]\tvalid_0's multi_logloss: 0.152308\n",
      "[168]\tvalid_0's multi_logloss: 0.152305\n",
      "[169]\tvalid_0's multi_logloss: 0.152301\n",
      "[170]\tvalid_0's multi_logloss: 0.152331\n",
      "[171]\tvalid_0's multi_logloss: 0.152304\n",
      "[172]\tvalid_0's multi_logloss: 0.152328\n",
      "[173]\tvalid_0's multi_logloss: 0.152322\n",
      "[174]\tvalid_0's multi_logloss: 0.152392\n",
      "[175]\tvalid_0's multi_logloss: 0.152404\n",
      "[176]\tvalid_0's multi_logloss: 0.152412\n",
      "[177]\tvalid_0's multi_logloss: 0.152424\n",
      "[178]\tvalid_0's multi_logloss: 0.152434\n",
      "[179]\tvalid_0's multi_logloss: 0.152417\n",
      "[180]\tvalid_0's multi_logloss: 0.152451\n",
      "[181]\tvalid_0's multi_logloss: 0.152445\n",
      "[182]\tvalid_0's multi_logloss: 0.15245\n",
      "[183]\tvalid_0's multi_logloss: 0.152494\n",
      "[184]\tvalid_0's multi_logloss: 0.15252\n",
      "[185]\tvalid_0's multi_logloss: 0.15252\n",
      "[186]\tvalid_0's multi_logloss: 0.152531\n",
      "[187]\tvalid_0's multi_logloss: 0.152523\n",
      "[188]\tvalid_0's multi_logloss: 0.152514\n",
      "[189]\tvalid_0's multi_logloss: 0.152548\n",
      "[190]\tvalid_0's multi_logloss: 0.152582\n",
      "[191]\tvalid_0's multi_logloss: 0.152626\n",
      "[192]\tvalid_0's multi_logloss: 0.15265\n",
      "[193]\tvalid_0's multi_logloss: 0.152683\n",
      "[194]\tvalid_0's multi_logloss: 0.152699\n",
      "[195]\tvalid_0's multi_logloss: 0.152735\n",
      "[196]\tvalid_0's multi_logloss: 0.15273\n",
      "[197]\tvalid_0's multi_logloss: 0.152765\n",
      "[198]\tvalid_0's multi_logloss: 0.152759\n",
      "[199]\tvalid_0's multi_logloss: 0.152792\n",
      "[200]\tvalid_0's multi_logloss: 0.152805\n",
      "[201]\tvalid_0's multi_logloss: 0.152837\n",
      "[202]\tvalid_0's multi_logloss: 0.152883\n",
      "[203]\tvalid_0's multi_logloss: 0.152873\n",
      "[204]\tvalid_0's multi_logloss: 0.152904\n",
      "[205]\tvalid_0's multi_logloss: 0.152948\n",
      "[206]\tvalid_0's multi_logloss: 0.152908\n",
      "[207]\tvalid_0's multi_logloss: 0.152937\n",
      "[208]\tvalid_0's multi_logloss: 0.152952\n",
      "[209]\tvalid_0's multi_logloss: 0.152915\n",
      "[210]\tvalid_0's multi_logloss: 0.152934\n",
      "[211]\tvalid_0's multi_logloss: 0.15294\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.151647\n",
      "training model for CV #10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016468883762015717, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016468883762015717\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.43499179721398096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.43499179721398096\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[1]\tvalid_0's multi_logloss: 0.849042\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.744152\n",
      "[3]\tvalid_0's multi_logloss: 0.657621\n",
      "[4]\tvalid_0's multi_logloss: 0.58925\n",
      "[5]\tvalid_0's multi_logloss: 0.535029\n",
      "[6]\tvalid_0's multi_logloss: 0.487428\n",
      "[7]\tvalid_0's multi_logloss: 0.450406\n",
      "[8]\tvalid_0's multi_logloss: 0.414225\n",
      "[9]\tvalid_0's multi_logloss: 0.381831\n",
      "[10]\tvalid_0's multi_logloss: 0.355847\n",
      "[11]\tvalid_0's multi_logloss: 0.334951\n",
      "[12]\tvalid_0's multi_logloss: 0.316914\n",
      "[13]\tvalid_0's multi_logloss: 0.299927\n",
      "[14]\tvalid_0's multi_logloss: 0.284822\n",
      "[15]\tvalid_0's multi_logloss: 0.272431\n",
      "[16]\tvalid_0's multi_logloss: 0.261151\n",
      "[17]\tvalid_0's multi_logloss: 0.250656\n",
      "[18]\tvalid_0's multi_logloss: 0.24004\n",
      "[19]\tvalid_0's multi_logloss: 0.231151\n",
      "[20]\tvalid_0's multi_logloss: 0.223352\n",
      "[21]\tvalid_0's multi_logloss: 0.21622\n",
      "[22]\tvalid_0's multi_logloss: 0.209667\n",
      "[23]\tvalid_0's multi_logloss: 0.204113\n",
      "[24]\tvalid_0's multi_logloss: 0.199831\n",
      "[25]\tvalid_0's multi_logloss: 0.19608\n",
      "[26]\tvalid_0's multi_logloss: 0.19173\n",
      "[27]\tvalid_0's multi_logloss: 0.188116\n",
      "[28]\tvalid_0's multi_logloss: 0.185054\n",
      "[29]\tvalid_0's multi_logloss: 0.182352\n",
      "[30]\tvalid_0's multi_logloss: 0.179707\n",
      "[31]\tvalid_0's multi_logloss: 0.177702\n",
      "[32]\tvalid_0's multi_logloss: 0.176046\n",
      "[33]\tvalid_0's multi_logloss: 0.174881\n",
      "[34]\tvalid_0's multi_logloss: 0.173343\n",
      "[35]\tvalid_0's multi_logloss: 0.172115\n",
      "[36]\tvalid_0's multi_logloss: 0.170823\n",
      "[37]\tvalid_0's multi_logloss: 0.170037\n",
      "[38]\tvalid_0's multi_logloss: 0.168963\n",
      "[39]\tvalid_0's multi_logloss: 0.167872\n",
      "[40]\tvalid_0's multi_logloss: 0.167101\n",
      "[41]\tvalid_0's multi_logloss: 0.166091\n",
      "[42]\tvalid_0's multi_logloss: 0.165139\n",
      "[43]\tvalid_0's multi_logloss: 0.164606\n",
      "[44]\tvalid_0's multi_logloss: 0.163799\n",
      "[45]\tvalid_0's multi_logloss: 0.163285\n",
      "[46]\tvalid_0's multi_logloss: 0.162605\n",
      "[47]\tvalid_0's multi_logloss: 0.162173\n",
      "[48]\tvalid_0's multi_logloss: 0.161844\n",
      "[49]\tvalid_0's multi_logloss: 0.16149\n",
      "[50]\tvalid_0's multi_logloss: 0.161208\n",
      "[51]\tvalid_0's multi_logloss: 0.160813\n",
      "[52]\tvalid_0's multi_logloss: 0.160425\n",
      "[53]\tvalid_0's multi_logloss: 0.159942\n",
      "[54]\tvalid_0's multi_logloss: 0.159569\n",
      "[55]\tvalid_0's multi_logloss: 0.159361\n",
      "[56]\tvalid_0's multi_logloss: 0.15919\n",
      "[57]\tvalid_0's multi_logloss: 0.15895\n",
      "[58]\tvalid_0's multi_logloss: 0.158717\n",
      "[59]\tvalid_0's multi_logloss: 0.158526\n",
      "[60]\tvalid_0's multi_logloss: 0.158339\n",
      "[61]\tvalid_0's multi_logloss: 0.158085\n",
      "[62]\tvalid_0's multi_logloss: 0.157946\n",
      "[63]\tvalid_0's multi_logloss: 0.157885\n",
      "[64]\tvalid_0's multi_logloss: 0.157725\n",
      "[65]\tvalid_0's multi_logloss: 0.157571\n",
      "[66]\tvalid_0's multi_logloss: 0.157534\n",
      "[67]\tvalid_0's multi_logloss: 0.157461\n",
      "[68]\tvalid_0's multi_logloss: 0.157339\n",
      "[69]\tvalid_0's multi_logloss: 0.157108\n",
      "[70]\tvalid_0's multi_logloss: 0.157066\n",
      "[71]\tvalid_0's multi_logloss: 0.157019\n",
      "[72]\tvalid_0's multi_logloss: 0.156968\n",
      "[73]\tvalid_0's multi_logloss: 0.156925\n",
      "[74]\tvalid_0's multi_logloss: 0.156835\n",
      "[75]\tvalid_0's multi_logloss: 0.156759\n",
      "[76]\tvalid_0's multi_logloss: 0.156657\n",
      "[77]\tvalid_0's multi_logloss: 0.156535\n",
      "[78]\tvalid_0's multi_logloss: 0.156458\n",
      "[79]\tvalid_0's multi_logloss: 0.156434\n",
      "[80]\tvalid_0's multi_logloss: 0.156377\n",
      "[81]\tvalid_0's multi_logloss: 0.15631\n",
      "[82]\tvalid_0's multi_logloss: 0.156265\n",
      "[83]\tvalid_0's multi_logloss: 0.156201\n",
      "[84]\tvalid_0's multi_logloss: 0.156125\n",
      "[85]\tvalid_0's multi_logloss: 0.156078\n",
      "[86]\tvalid_0's multi_logloss: 0.156037\n",
      "[87]\tvalid_0's multi_logloss: 0.156044\n",
      "[88]\tvalid_0's multi_logloss: 0.155997\n",
      "[89]\tvalid_0's multi_logloss: 0.155983\n",
      "[90]\tvalid_0's multi_logloss: 0.15595\n",
      "[91]\tvalid_0's multi_logloss: 0.155926\n",
      "[92]\tvalid_0's multi_logloss: 0.155917\n",
      "[93]\tvalid_0's multi_logloss: 0.155884\n",
      "[94]\tvalid_0's multi_logloss: 0.155859\n",
      "[95]\tvalid_0's multi_logloss: 0.155874\n",
      "[96]\tvalid_0's multi_logloss: 0.155874\n",
      "[97]\tvalid_0's multi_logloss: 0.155889\n",
      "[98]\tvalid_0's multi_logloss: 0.155852\n",
      "[99]\tvalid_0's multi_logloss: 0.155838\n",
      "[100]\tvalid_0's multi_logloss: 0.155812\n",
      "[101]\tvalid_0's multi_logloss: 0.155797\n",
      "[102]\tvalid_0's multi_logloss: 0.155803\n",
      "[103]\tvalid_0's multi_logloss: 0.155809\n",
      "[104]\tvalid_0's multi_logloss: 0.155873\n",
      "[105]\tvalid_0's multi_logloss: 0.155866\n",
      "[106]\tvalid_0's multi_logloss: 0.155856\n",
      "[107]\tvalid_0's multi_logloss: 0.155832\n",
      "[108]\tvalid_0's multi_logloss: 0.155835\n",
      "[109]\tvalid_0's multi_logloss: 0.155825\n",
      "[110]\tvalid_0's multi_logloss: 0.155823\n",
      "[111]\tvalid_0's multi_logloss: 0.155857\n",
      "[112]\tvalid_0's multi_logloss: 0.155888\n",
      "[113]\tvalid_0's multi_logloss: 0.15587\n",
      "[114]\tvalid_0's multi_logloss: 0.155853\n",
      "[115]\tvalid_0's multi_logloss: 0.155885\n",
      "[116]\tvalid_0's multi_logloss: 0.155827\n",
      "[117]\tvalid_0's multi_logloss: 0.155819\n",
      "[118]\tvalid_0's multi_logloss: 0.155813\n",
      "[119]\tvalid_0's multi_logloss: 0.155825\n",
      "[120]\tvalid_0's multi_logloss: 0.155837\n",
      "[121]\tvalid_0's multi_logloss: 0.155845\n",
      "[122]\tvalid_0's multi_logloss: 0.155853\n",
      "[123]\tvalid_0's multi_logloss: 0.155852\n",
      "[124]\tvalid_0's multi_logloss: 0.155864\n",
      "[125]\tvalid_0's multi_logloss: 0.155863\n",
      "[126]\tvalid_0's multi_logloss: 0.155859\n",
      "[127]\tvalid_0's multi_logloss: 0.155877\n",
      "[128]\tvalid_0's multi_logloss: 0.155861\n",
      "[129]\tvalid_0's multi_logloss: 0.155859\n",
      "[130]\tvalid_0's multi_logloss: 0.155869\n",
      "[131]\tvalid_0's multi_logloss: 0.155872\n",
      "[132]\tvalid_0's multi_logloss: 0.155901\n",
      "[133]\tvalid_0's multi_logloss: 0.155878\n",
      "[134]\tvalid_0's multi_logloss: 0.155879\n",
      "[135]\tvalid_0's multi_logloss: 0.15587\n",
      "[136]\tvalid_0's multi_logloss: 0.15588\n",
      "[137]\tvalid_0's multi_logloss: 0.155863\n",
      "[138]\tvalid_0's multi_logloss: 0.155908\n",
      "[139]\tvalid_0's multi_logloss: 0.155903\n",
      "[140]\tvalid_0's multi_logloss: 0.155909\n",
      "[141]\tvalid_0's multi_logloss: 0.155933\n",
      "[142]\tvalid_0's multi_logloss: 0.155947\n",
      "[143]\tvalid_0's multi_logloss: 0.155943\n",
      "[144]\tvalid_0's multi_logloss: 0.15597\n",
      "[145]\tvalid_0's multi_logloss: 0.155981\n",
      "[146]\tvalid_0's multi_logloss: 0.155978\n",
      "[147]\tvalid_0's multi_logloss: 0.156011\n",
      "[148]\tvalid_0's multi_logloss: 0.156037\n",
      "[149]\tvalid_0's multi_logloss: 0.156051\n",
      "[150]\tvalid_0's multi_logloss: 0.156078\n",
      "[151]\tvalid_0's multi_logloss: 0.156095\n",
      "[152]\tvalid_0's multi_logloss: 0.15615\n",
      "[153]\tvalid_0's multi_logloss: 0.15616\n",
      "[154]\tvalid_0's multi_logloss: 0.156188\n",
      "[155]\tvalid_0's multi_logloss: 0.156224\n",
      "[156]\tvalid_0's multi_logloss: 0.156245\n",
      "[157]\tvalid_0's multi_logloss: 0.156266\n",
      "[158]\tvalid_0's multi_logloss: 0.156248\n",
      "[159]\tvalid_0's multi_logloss: 0.156257\n",
      "[160]\tvalid_0's multi_logloss: 0.156257\n",
      "[161]\tvalid_0's multi_logloss: 0.156283\n",
      "[162]\tvalid_0's multi_logloss: 0.156328\n",
      "[163]\tvalid_0's multi_logloss: 0.156339\n",
      "[164]\tvalid_0's multi_logloss: 0.156365\n",
      "[165]\tvalid_0's multi_logloss: 0.156372\n",
      "[166]\tvalid_0's multi_logloss: 0.156385\n",
      "[167]\tvalid_0's multi_logloss: 0.156454\n",
      "[168]\tvalid_0's multi_logloss: 0.156486\n",
      "[169]\tvalid_0's multi_logloss: 0.156545\n",
      "[170]\tvalid_0's multi_logloss: 0.156546\n",
      "[171]\tvalid_0's multi_logloss: 0.156589\n",
      "[172]\tvalid_0's multi_logloss: 0.156583\n",
      "[173]\tvalid_0's multi_logloss: 0.156569\n",
      "[174]\tvalid_0's multi_logloss: 0.156576\n",
      "[175]\tvalid_0's multi_logloss: 0.156591\n",
      "[176]\tvalid_0's multi_logloss: 0.156609\n",
      "[177]\tvalid_0's multi_logloss: 0.156653\n",
      "[178]\tvalid_0's multi_logloss: 0.156665\n",
      "[179]\tvalid_0's multi_logloss: 0.156677\n",
      "[180]\tvalid_0's multi_logloss: 0.156715\n",
      "[181]\tvalid_0's multi_logloss: 0.156737\n",
      "[182]\tvalid_0's multi_logloss: 0.156766\n",
      "[183]\tvalid_0's multi_logloss: 0.156772\n",
      "[184]\tvalid_0's multi_logloss: 0.156788\n",
      "[185]\tvalid_0's multi_logloss: 0.156825\n",
      "[186]\tvalid_0's multi_logloss: 0.156844\n",
      "[187]\tvalid_0's multi_logloss: 0.156887\n",
      "[188]\tvalid_0's multi_logloss: 0.156955\n",
      "[189]\tvalid_0's multi_logloss: 0.156952\n",
      "[190]\tvalid_0's multi_logloss: 0.156988\n",
      "[191]\tvalid_0's multi_logloss: 0.157019\n",
      "[192]\tvalid_0's multi_logloss: 0.157043\n",
      "[193]\tvalid_0's multi_logloss: 0.157054\n",
      "[194]\tvalid_0's multi_logloss: 0.157103\n",
      "[195]\tvalid_0's multi_logloss: 0.157082\n",
      "[196]\tvalid_0's multi_logloss: 0.157131\n",
      "[197]\tvalid_0's multi_logloss: 0.157156\n",
      "[198]\tvalid_0's multi_logloss: 0.157188\n",
      "[199]\tvalid_0's multi_logloss: 0.1572\n",
      "[200]\tvalid_0's multi_logloss: 0.157183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\tvalid_0's multi_logloss: 0.15725\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.155797\n"
     ]
    }
   ],
   "source": [
    "p_val = np.zeros((trn.shape[0], n_class))\n",
    "p_tst = np.zeros((tst.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(trn[i_trn], y[i_trn],\n",
    "            eval_set=[(trn[i_val], y[i_val])],\n",
    "            eval_metric='multiclass',\n",
    "            early_stopping_rounds=10)\n",
    "    \n",
    "    p_val[i_val, :] = clf.predict_proba(trn[i_val])\n",
    "    p_tst += clf.predict_proba(tst) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:00.428750Z",
     "start_time": "2020-10-05T08:54:00.363125Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7d51b48fcae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{accuracy_score(y, np.argmax(p_val, axis=1)) * 100:.4f}%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy_score(y, np.argmax(p_val, axis=1)) * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:00.469957Z",
     "start_time": "2020-10-05T08:54:00.431515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000, 3) (80000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(p_val.shape, p_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:01.328066Z",
     "start_time": "2020-10-05T08:54:00.472868Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피처 중요도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:01.664554Z",
     "start_time": "2020-10-05T08:54:01.331052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='feature'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp = pd.DataFrame({'feature': df.columns, 'importance': clf.feature_importances_})\n",
    "imp = imp.sort_values('importance').set_index('feature')\n",
    "imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:01.717722Z",
     "start_time": "2020-10-05T08:54:01.667076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320002</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class\n",
       "id           \n",
       "320000      0\n",
       "320001      0\n",
       "320002      0\n",
       "320003      0\n",
       "320004      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(sample_file, index_col=0)\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:01.754346Z",
     "start_time": "2020-10-05T08:54:01.720089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320002</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320004</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class\n",
       "id           \n",
       "320000      2\n",
       "320001      0\n",
       "320002      2\n",
       "320003      0\n",
       "320004      2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[target_col] = np.argmax(p_tst, axis=1)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:01.788659Z",
     "start_time": "2020-10-05T08:54:01.756610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    40743\n",
       "0    29974\n",
       "1     9283\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[target_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T08:54:01.936033Z",
     "start_time": "2020-10-05T08:54:01.791219Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv(sub_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
